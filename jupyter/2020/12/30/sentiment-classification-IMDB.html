<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Sentiment classification | Ashish Kashav</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Sentiment classification" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The task of classifying sentiments of texts (for example movie or product reviews) has high practical significance in online marketing as well as financial prediction. This is a non-trivial task, since the concept of sentiment is not easily captured. IMDB sentiment benchmark dataset from Stanford is used." />
<meta property="og:description" content="The task of classifying sentiments of texts (for example movie or product reviews) has high practical significance in online marketing as well as financial prediction. This is a non-trivial task, since the concept of sentiment is not easily captured. IMDB sentiment benchmark dataset from Stanford is used." />
<link rel="canonical" href="https://ashish244co.github.io/blog/jupyter/2020/12/30/sentiment-classification-IMDB.html" />
<meta property="og:url" content="https://ashish244co.github.io/blog/jupyter/2020/12/30/sentiment-classification-IMDB.html" />
<meta property="og:site_name" content="Ashish Kashav" />
<meta property="og:image" content="https://ashish244co.github.io/blog/images/chart-preview.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-12-30T00:00:00-06:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://ashish244co.github.io/blog/images/chart-preview.png" />
<meta property="twitter:title" content="Sentiment classification" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2020-12-30T00:00:00-06:00","datePublished":"2020-12-30T00:00:00-06:00","description":"The task of classifying sentiments of texts (for example movie or product reviews) has high practical significance in online marketing as well as financial prediction. This is a non-trivial task, since the concept of sentiment is not easily captured. IMDB sentiment benchmark dataset from Stanford is used.","headline":"Sentiment classification","image":"https://ashish244co.github.io/blog/images/chart-preview.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://ashish244co.github.io/blog/jupyter/2020/12/30/sentiment-classification-IMDB.html"},"url":"https://ashish244co.github.io/blog/jupyter/2020/12/30/sentiment-classification-IMDB.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://ashish244co.github.io/blog/feed.xml" title="Ashish Kashav" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Ashish Kashav</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Sentiment classification</h1><p class="page-description">The task of classifying sentiments of texts (for example movie or product reviews) has high practical significance in online marketing as well as financial prediction. This is a non-trivial task, since the concept of sentiment is not easily captured. <a href='https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'>IMDB sentiment</a> benchmark dataset from Stanford is used.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-12-30T00:00:00-06:00" itemprop="datePublished">
        Dec 30, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      33 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#jupyter">jupyter</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/ashish244co/blog/tree/master/_notebooks/2020-12-30-sentiment-classification-IMDB.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/ashish244co/blog/master?filepath=_notebooks%2F2020-12-30-sentiment-classification-IMDB.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/ashish244co/blog/blob/master/_notebooks/2020-12-30-sentiment-classification-IMDB.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fashish244co%2Fblog%2Fblob%2Fmaster%2F_notebooks%2F2020-12-30-sentiment-classification-IMDB.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/blog/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#Data-download">Data download </a></li>
<li class="toc-entry toc-h1"><a href="#Alternative-with-tf.datasets">Alternative with tf.datasets </a></li>
<li class="toc-entry toc-h1"><a href="#Cleaning">Cleaning </a></li>
<li class="toc-entry toc-h1"><a href="#Modelling">Modelling </a></li>
<li class="toc-entry toc-h1"><a href="#FAST-TEXT">FAST TEXT </a></li>
<li class="toc-entry toc-h1"><a href="#Sequence-RNN">Sequence RNN </a></li>
<li class="toc-entry toc-h1"><a href="#BERT-BASED">BERT BASED </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-12-30-sentiment-classification-IMDB.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Data-download">
<a class="anchor" href="#Data-download" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data download<a class="anchor-link" href="#Data-download"> </a>
</h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz
<span class="o">!</span>tar -xzf aclImdb_v1.tar.gz
<span class="o">!</span>ls
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>--2020-12-04 12:11:02--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz
Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10
Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 84125825 (80M) [application/x-gzip]
Saving to: â€˜aclImdb_v1.tar.gzâ€™

aclImdb_v1.tar.gz   100%[===================&gt;]  80.23M  20.3MB/s    in 7.1s    

2020-12-04 12:11:09 (11.3 MB/s) - â€˜aclImdb_v1.tar.gzâ€™ saved [84125825/84125825]

aclImdb  aclImdb_v1.tar.gz  sample_data
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Alternative-with-tf.datasets">
<a class="anchor" href="#Alternative-with-tf.datasets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Alternative with tf.datasets<a class="anchor-link" href="#Alternative-with-tf.datasets"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I imported data in my own way since i thought it would be a good idea to do semi supervised traiing also using the unsupervised text.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">read_file</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">'rt'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
        <span class="n">text</span> <span class="o">=</span> <span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">text</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">os</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">getData</span><span class="p">():</span>
    <span class="n">path_posttrain</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">'aclImdb/train/'</span><span class="p">,</span> <span class="s2">"pos"</span><span class="p">,</span> <span class="s2">"*.txt"</span><span class="p">)</span>
    <span class="n">path_negtrain</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">'aclImdb/train/'</span><span class="p">,</span> <span class="s2">"neg"</span><span class="p">,</span> <span class="s2">"*.txt"</span><span class="p">)</span>
    <span class="n">postrain</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">path_posttrain</span><span class="p">)</span>
    <span class="n">negtrain</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">path_negtrain</span><span class="p">)</span>
    <span class="n">data_pos_train</span> <span class="o">=</span> <span class="p">[</span><span class="n">read_file</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">postrain</span><span class="p">]</span>
    <span class="n">data_neg_train</span> <span class="o">=</span> <span class="p">[</span><span class="n">read_file</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">negtrain</span><span class="p">]</span>  
    

    <span class="n">path_unsup</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">'aclImdb/train/'</span><span class="p">,</span> <span class="s2">"unsup"</span><span class="p">,</span> <span class="s2">"*.txt"</span><span class="p">)</span>
    <span class="n">unsup</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">path_unsup</span><span class="p">)</span>
    <span class="n">unsup_train</span> <span class="o">=</span> <span class="p">[</span><span class="n">read_file</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">unsup</span><span class="p">]</span>  


    <span class="n">path_postest</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">'aclImdb/test/'</span><span class="p">,</span> <span class="s2">"pos"</span><span class="p">,</span> <span class="s2">"*.txt"</span><span class="p">)</span>
    <span class="n">path_negtest</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">'aclImdb/test/'</span><span class="p">,</span> <span class="s2">"neg"</span><span class="p">,</span> <span class="s2">"*.txt"</span><span class="p">)</span>
    <span class="n">postest</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">path_postest</span><span class="p">)</span>
    <span class="n">negtest</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">path_negtest</span><span class="p">)</span>

    <span class="n">data_pos_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">read_file</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">postest</span><span class="p">]</span>
    <span class="n">data_neg_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">read_file</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">negtest</span><span class="p">]</span>  


    <span class="k">return</span> <span class="n">data_pos_train</span><span class="o">+</span><span class="n">data_neg_train</span><span class="p">,[</span><span class="mf">1.0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_pos_train</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_neg_train</span><span class="p">),</span><span class="n">data_pos_test</span><span class="o">+</span><span class="n">data_neg_test</span><span class="p">,[</span><span class="mf">1.0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_pos_test</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_neg_test</span><span class="p">),</span><span class="n">unsup_train</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainX</span><span class="p">,</span><span class="n">trainY</span><span class="p">,</span><span class="n">testX</span><span class="p">,</span><span class="n">testY</span><span class="p">,</span><span class="n">unsup</span><span class="o">=</span><span class="n">getData</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainX</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">trainY</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>("A couple(Janet and Richard) go camping out in the woods near a giant swamp. After camping and enjoying nature, the couple takes shelter in what they think is an abandoned farm house. Soon, a pair of escaped convicts show up and, after much delaying of the inevitable, they proceed to rape Janet and lock Richard in a birdcage.&lt;br /&gt;&lt;br /&gt;This LAST HOUSE ON THE LEFT-like film has to be one of the most underrated horror films ever made. It's one of the more sick and twisted early 70s shockers. Moreover, I found this to be quite enchanting and beautiful in it's perverse tone. I love CAGED TERROR. The music definitely helps lend a sense of personality to the film as well as a lot of beauty. I found the film to be quite creepy.&lt;br /&gt;&lt;br /&gt;The flaws mainly have to do with the pacing of the film, which is to say that the film is rather slow and meandering. While I didn't mind the pacing due to the beauty and suspense of the film in question, I do think that it will both most people. The acting isn't too good nor is the dialogue, at least in the early scenes. This film takes a little more patience than usual, and it's really not for everyone.&lt;br /&gt;&lt;br /&gt;In short, this was a good film. Not the greatest horror film I've ever seen, but it is certainly a lot of fun. It's not exactly the easiest film to find. It's possible to find it in the USED section of a lot of stores if you look hard enough. It's not for everyone, but if you're a fan of trash cinema then it's definitely worth checking out.",
 1.0)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">testX</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">testY</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>("This Metro film is episodic, but nearly a constant series of chases, mainly trying to escape police, whether real or imagined, as Buster is mistaken for an escaped criminal. It is consistently inventive and entertaining. Its greatest value is in its documenting what Hollywood looked like in the early twenties, since 95% of it is shot outside among the streets and building exteriors of the time. One gem moment and one gem sequence are present here.&lt;br /&gt;&lt;br /&gt;The great moment is when a train at a great distance quickly approaches the camera and finally stops just short of it - with Buster glumly sitting on the cowcatcher and thus moving from a long shot to a close-up within seconds.&lt;br /&gt;&lt;br /&gt;The great sequence is with the phone booth next to the elevator - one constantly being mistaken for the other with races from floor to floor - one of the great Keaton gags.&lt;br /&gt;&lt;br /&gt;Kino's print is sharp and clear - almost pristine. There is a violin/piano score accompaniment. This is one to seek out and enjoy.",
 1.0)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">unsupDf</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">unsup</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainDf</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">testDf</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainDf</span><span class="p">[</span><span class="s1">'Label'</span><span class="p">]</span><span class="o">=</span><span class="n">trainY</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">testDf</span><span class="p">[</span><span class="s1">'Label'</span><span class="p">]</span><span class="o">=</span><span class="n">testY</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainDf</span><span class="o">=</span><span class="n">trainDf</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">testDf</span><span class="o">=</span><span class="n">testDf</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainDf</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">'train.csv'</span><span class="p">)</span>
<span class="n">testDf</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">'test.csv'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainPlusUnsupDf</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">unsupDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">],</span><span class="n">trainDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainPlusUnsupDf</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">trainPlusUnsupDf</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I use spacy here for text preprocessing for bag  of words based model which i use as a tokenizer in the input of tfidf vectorizer. So spacy here toenizes and cleans as well.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%capture</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">spacy</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">en_core_web_sm</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">optuna</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Diabled tagger and other part of pipelines since they take it takes a lot of time to run or else.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"en_core_web_sm"</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="p">[</span><span class="s1">'parser'</span><span class="p">,</span> <span class="s1">'ner'</span><span class="p">,</span><span class="s1">'tagger'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nlp</span><span class="o">.</span><span class="n">Defaults</span><span class="o">.</span><span class="n">stop_words</span><span class="o">.</span><span class="n">update</span><span class="p">([</span><span class="s1">'from'</span><span class="p">,</span> <span class="s1">'subject'</span><span class="p">,</span> <span class="s1">'re'</span><span class="p">,</span> <span class="s1">'edu'</span><span class="p">,</span> <span class="s1">'use'</span><span class="p">,</span> <span class="s1">'not'</span><span class="p">,</span> 
                               <span class="s1">'would'</span><span class="p">,</span> <span class="s1">'say'</span><span class="p">,</span> <span class="s1">'could'</span><span class="p">,</span> <span class="s1">'_'</span><span class="p">,</span> <span class="s1">'be'</span><span class="p">,</span> <span class="s1">'know'</span><span class="p">,</span> <span class="s1">'good'</span><span class="p">,</span> 
                               <span class="s1">'go'</span><span class="p">,</span> <span class="s1">'get'</span><span class="p">,</span> <span class="s1">'do'</span><span class="p">,</span> <span class="s1">'done'</span><span class="p">,</span> <span class="s1">'try'</span><span class="p">,</span> <span class="s1">'many'</span><span class="p">,</span> <span class="s1">'some'</span><span class="p">,</span>
                               <span class="s1">'nice'</span><span class="p">,</span> <span class="s1">'thank'</span><span class="p">,</span> <span class="s1">'think'</span><span class="p">,</span> <span class="s1">'see'</span><span class="p">,</span> <span class="s1">'rather'</span><span class="p">,</span> <span class="s1">'easy'</span><span class="p">,</span> <span class="s1">'easily'</span><span class="p">,</span>
                               <span class="s1">'lot'</span><span class="p">,</span> <span class="s1">'lack'</span><span class="p">,</span> <span class="s1">'make'</span><span class="p">,</span> <span class="s1">'want'</span><span class="p">,</span> <span class="s1">'seem'</span><span class="p">,</span> <span class="s1">'run'</span><span class="p">,</span> <span class="s1">'need'</span><span class="p">,</span> <span class="s1">'even'</span><span class="p">,</span>
                               <span class="s1">'right'</span><span class="p">,</span> <span class="s1">'line'</span><span class="p">,</span> <span class="s1">'even'</span><span class="p">,</span> <span class="s1">'also'</span><span class="p">,</span> <span class="s1">'may'</span><span class="p">,</span> <span class="s1">'take'</span><span class="p">,</span> <span class="s1">'come'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">string</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>also using regex for basic text preprocessing for deep learning and fastext models. which i just clearing html texts ensuring only alphanumeric characters are there and replacing number with  num tag.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Cleaning">
<a class="anchor" href="#Cleaning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cleaning<a class="anchor-link" href="#Cleaning"> </a>
</h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>
<span class="k">def</span> <span class="nf">alpha_num</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'[^A-Za-z0-9 ]'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    
<span class="c1">#a good idea to replace all the numbers with a special token</span>
<span class="k">def</span> <span class="nf">replace_num</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'[0-9]'</span><span class="p">,</span> <span class="s1">'__NUM__'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainPlusUnsupDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span> <span class="o">=</span> <span class="n">trainPlusUnsupDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
<span class="n">trainPlusUnsupDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">=</span>  <span class="n">trainPlusUnsupDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="s1">'html.parser'</span><span class="p">)</span><span class="o">.</span><span class="n">get_text</span><span class="p">())</span>
<span class="n">trainPlusUnsupDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span> <span class="o">=</span> <span class="n">trainPlusUnsupDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">alpha_num</span><span class="p">)</span>
<span class="n">trainPlusUnsupDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span> <span class="o">=</span> <span class="n">trainPlusUnsupDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">replace_num</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">spacyTokenize</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
  <span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
  <span class="n">text_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">text_words</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">tokenizerBOW</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
  <span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
  <span class="n">text_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span> <span class="k">if</span> <span class="n">token</span><span class="o">.</span><span class="n">is_alpha</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">token</span><span class="o">.</span><span class="n">is_stop</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">token</span><span class="o">.</span><span class="n">is_digit</span> <span class="ow">and</span> <span class="n">token</span><span class="o">.</span><span class="n">text</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">]</span>
  <span class="n">text_words</span> <span class="o">=</span> <span class="p">[</span> <span class="n">token</span><span class="o">.</span><span class="n">lemma_</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">if</span> <span class="n">token</span><span class="o">.</span><span class="n">lemma_</span> <span class="o">!=</span> <span class="s2">"-PRON-"</span> <span class="k">else</span> <span class="n">token</span><span class="o">.</span><span class="n">lower_</span>  <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">text_words</span> <span class="p">]</span>
  <span class="k">return</span> <span class="n">text_words</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The tokenizer also automatically lemmatise and removes stop words and puncuations and other basic checks using spacy.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="n">trainPlusUnsupDf</span><span class="p">[</span><span class="s1">'TextTOK'</span><span class="p">]</span><span class="o">=</span><span class="n">trainPlusUnsupDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">spacyTokenize</span><span class="p">)</span>
<span class="n">trainPlusUnsupDf</span><span class="p">[</span><span class="s1">'length'</span><span class="p">]</span><span class="o">=</span><span class="n">trainPlusUnsupDf</span><span class="p">[</span><span class="s1">'TextTOK'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 1min 12s, sys: 681 ms, total: 1min 13s
Wall time: 1min 13s
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainPlusUnsupDf</span><span class="p">[</span><span class="s1">'length'</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>count    75000.000000
mean       237.455867
std        175.447057
min          9.000000
25%        129.000000
50%        178.000000
75%        288.000000
max       2503.000000
Name: length, dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">trainPlusUnsupDf</span><span class="p">[</span><span class="s1">'length'</span><span class="p">],</span><span class="n">kde</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
  warnings.warn(msg, FutureWarning)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f0f383a8c18&gt;</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>here we can see the distribution of length of input text mostly here i guess maxlen of 300 will be a good idea which kind of cover approx till 75 percentile of all the texts.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">TruncatedSVD</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">sparse</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">pipelineBOW</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
  <span class="n">tfidfVectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizerBOW</span><span class="p">,</span><span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span><span class="n">sublinear_tf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">strip_accents</span><span class="o">=</span><span class="s1">'unicode'</span><span class="p">,</span><span class="n">max_features</span> <span class="o">=</span> <span class="mi">40000</span><span class="p">)</span> 
  <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
  <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="s1">'html.parser'</span><span class="p">)</span><span class="o">.</span><span class="n">get_text</span><span class="p">())</span>
  <span class="n">tfidfVectorizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'TFIDF Done'</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tfidfVectorizer</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">processData</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">tfidfVectorizer</span><span class="p">):</span>
  <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
  <span class="n">data</span><span class="o">=</span><span class="n">tfidfVectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">data</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Modelling">
<a class="anchor" href="#Modelling" aria-hidden="true"><span class="octicon octicon-link"></span></a>Modelling<a class="anchor-link" href="#Modelling"> </a>
</h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">model_selection</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainPlusUnsupDf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Text</th>
      <th>TextTOK</th>
      <th>length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>oil industrialist leonard dawson had a __NUM__...</td>
      <td>[oil, industrialist, leonard, dawson, had, a, ...</td>
      <td>213</td>
    </tr>
    <tr>
      <th>1</th>
      <td>having recently revisited my old van damme col...</td>
      <td>[having, recently, revisited, my, old, van, da...</td>
      <td>940</td>
    </tr>
    <tr>
      <th>2</th>
      <td>i thought this might be funny going in and tay...</td>
      <td>[i, thought, this, might, be, funny, going, in...</td>
      <td>210</td>
    </tr>
    <tr>
      <th>3</th>
      <td>one of the many movies that mistakes profanity...</td>
      <td>[one, of, the, many, movies, that, mistakes, p...</td>
      <td>132</td>
    </tr>
    <tr>
      <th>4</th>
      <td>god will forgive them etc this is the best lin...</td>
      <td>[god, will, forgive, them, etc, this, is, the,...</td>
      <td>245</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="n">tfidfVectorizer</span><span class="o">=</span><span class="n">pipelineBOW</span><span class="p">(</span><span class="n">trainPlusUnsupDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn("The parameter 'token_pattern' will not be used"
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>TFIDF Done
CPU times: user 3min 11s, sys: 366 ms, total: 3min 11s
Wall time: 3min 11s
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="n">train</span><span class="o">=</span><span class="n">processData</span><span class="p">(</span><span class="n">trainDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">],</span><span class="n">tfidfVectorizer</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 45.7 s, sys: 0 ns, total: 45.7 s
Wall time: 45.7 s
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="n">test</span><span class="o">=</span><span class="n">processData</span><span class="p">(</span><span class="n">testDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">],</span><span class="n">tfidfVectorizer</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 43.9 s, sys: 0 ns, total: 43.9 s
Wall time: 43.9 s
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">optuna</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Instead of handpickin parameter by myselfi automated the whole process using opuna where he choice of models are linear support vector machines, random forest and logistic regression.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Optuna by default uses TPE sampler.</p>
<p>According to the documentation:</p>
<p>This sampler is based on independent sampling. See also BaseSampler for more details of â€˜independent samplingâ€™.</p>
<p>On each trial, for each parameter, TPE fits one Gaussian Mixture Model (GMM) l(x) to the set of parameter values associated with the best objective values, and another GMM g(x) to the remaining parameter values. It chooses the parameter value x that maximizes the ratio l(x)/g(x).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="k">def</span> <span class="nf">objectiveSklearn</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>

    <span class="n">classifier_name</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="s1">'classifier'</span><span class="p">,</span> <span class="p">[</span><span class="s1">'LogReg'</span><span class="p">,</span><span class="s1">'SVC'</span><span class="p">,</span><span class="s1">'RandomForest'</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">classifier_name</span> <span class="o">==</span> <span class="s1">'LogReg'</span><span class="p">:</span>
         <span class="n">loss</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">,</span> <span class="p">[</span><span class="s1">'l1'</span><span class="p">,</span> <span class="s1">'l2'</span><span class="p">,</span> <span class="s1">'elasticnet'</span><span class="p">])</span>
         <span class="n">classifier_obj</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="s1">'balanced'</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">classifier_name</span> <span class="o">==</span> <span class="s1">'SVC'</span><span class="p">):</span>
        <span class="n">svc_c</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">"c"</span><span class="p">,</span> <span class="mf">1e-10</span><span class="p">,</span> <span class="mf">1e10</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">classifier_obj</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">svc_c</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">rf_max_depth</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s1">'rf_max_depth'</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
        <span class="n">n_est</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="s2">"n_estimator"</span><span class="p">,</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">,</span><span class="mi">300</span><span class="p">,</span><span class="mi">400</span><span class="p">,</span><span class="mi">500</span><span class="p">]))</span>
        <span class="n">classifier_obj</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">rf_max_depth</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="n">n_est</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">accuracy</span><span class="o">=</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">classifier_obj</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">trainDf</span><span class="p">[</span><span class="s1">'Label'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>

<span class="n">studySK</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s1">'maximize'</span><span class="p">)</span>
<span class="n">studySK</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objectiveSklearn</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre><span class="ansi-green-fg">[I 2020-12-04 13:28:48,002]</span> A new study created in memory with name: no-name-1b77f598-6c55-4079-b4cf-c6288f590dbe
<span class="ansi-green-fg">[I 2020-12-04 13:29:14,304]</span> Trial 0 finished with value: 0.8346396922831557 and parameters: {'classifier': 'LogReg', 'loss': 'l2', 'rf_max_depth': 12, 'n_estimator': 400}. Best is trial 0 with value: 0.8346396922831557.
<span class="ansi-green-fg">[I 2020-12-04 13:29:22,459]</span> Trial 1 finished with value: 0.8660798555772325 and parameters: {'classifier': 'SVC', 'c': 1112.8121932926088}. Best is trial 1 with value: 0.8660798555772325.
<span class="ansi-green-fg">[I 2020-12-04 13:29:24,040]</span> Trial 2 finished with value: 0.870639869991248 and parameters: {'classifier': 'SVC', 'c': 6.091001448466234}. Best is trial 2 with value: 0.870639869991248.
<span class="ansi-green-fg">[I 2020-12-04 13:29:37,624]</span> Trial 3 finished with value: 0.8310396010752837 and parameters: {'classifier': 'LogReg', 'loss': 'l1', 'rf_max_depth': 6, 'n_estimator': 400}. Best is trial 2 with value: 0.870639869991248.
<span class="ansi-green-fg">[I 2020-12-04 13:29:43,109]</span> Trial 4 finished with value: 0.8146395882233177 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 4, 'n_estimator': 200}. Best is trial 2 with value: 0.870639869991248.
<span class="ansi-green-fg">[I 2020-12-04 13:30:11,168]</span> Trial 5 finished with value: 0.8359996170905152 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 11, 'n_estimator': 500}. Best is trial 2 with value: 0.870639869991248.
<span class="ansi-green-fg">[I 2020-12-04 13:30:12,967]</span> Trial 6 finished with value: 0.8660398539771684 and parameters: {'classifier': 'SVC', 'c': 34653.80363906542}. Best is trial 2 with value: 0.870639869991248.
<span class="ansi-green-fg">[I 2020-12-04 13:30:14,739]</span> Trial 7 finished with value: 0.8660398539771684 and parameters: {'classifier': 'SVC', 'c': 6089723.822115924}. Best is trial 2 with value: 0.870639869991248.
<span class="ansi-green-fg">[I 2020-12-04 13:30:28,199]</span> Trial 8 finished with value: 0.827719765858069 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 6, 'n_estimator': 400}. Best is trial 2 with value: 0.870639869991248.
<span class="ansi-green-fg">[I 2020-12-04 13:30:41,732]</span> Trial 9 finished with value: 0.8342797162810438 and parameters: {'classifier': 'LogReg', 'loss': 'elasticnet', 'rf_max_depth': 13, 'n_estimator': 200}. Best is trial 2 with value: 0.870639869991248.
<span class="ansi-green-fg">[I 2020-12-04 13:30:42,019]</span> Trial 10 finished with value: 0.821519594645077 and parameters: {'classifier': 'SVC', 'c': 3.640261501310243e-07}. Best is trial 2 with value: 0.870639869991248.
<span class="ansi-green-fg">[I 2020-12-04 13:30:42,450]</span> Trial 11 finished with value: 0.8631596859746721 and parameters: {'classifier': 'SVC', 'c': 0.019657026783969394}. Best is trial 2 with value: 0.870639869991248.
<span class="ansi-green-fg">[I 2020-12-04 13:30:44,891]</span> Trial 12 finished with value: 0.8689198827852321 and parameters: {'classifier': 'SVC', 'c': 11.204722563404262}. Best is trial 2 with value: 0.870639869991248.
<span class="ansi-green-fg">[I 2020-12-04 13:30:45,325]</span> Trial 13 finished with value: 0.8796797996229905 and parameters: {'classifier': 'SVC', 'c': 0.08395483786035728}. Best is trial 13 with value: 0.8796797996229905.
<span class="ansi-green-fg">[I 2020-12-04 13:30:45,637]</span> Trial 14 finished with value: 0.8316796266763077 and parameters: {'classifier': 'SVC', 'c': 0.00016477035976404718}. Best is trial 13 with value: 0.8796797996229905.
<span class="ansi-green-fg">[I 2020-12-04 13:30:45,876]</span> Trial 15 finished with value: 0.820759588242901 and parameters: {'classifier': 'SVC', 'c': 1.6781273218095836e-10}. Best is trial 13 with value: 0.8796797996229905.
<span class="ansi-green-fg">[I 2020-12-04 13:30:47,688]</span> Trial 16 finished with value: 0.8660398539771684 and parameters: {'classifier': 'SVC', 'c': 3470240422.013036}. Best is trial 13 with value: 0.8796797996229905.
<span class="ansi-green-fg">[I 2020-12-04 13:30:48,115]</span> Trial 17 finished with value: 0.8726396620059665 and parameters: {'classifier': 'SVC', 'c': 0.041590138298862295}. Best is trial 13 with value: 0.8796797996229905.
<span class="ansi-green-fg">[I 2020-12-04 13:30:48,454]</span> Trial 18 finished with value: 0.8322796026791875 and parameters: {'classifier': 'SVC', 'c': 3.794433800671928e-05}. Best is trial 13 with value: 0.8796797996229905.
<span class="ansi-green-fg">[I 2020-12-04 13:30:48,881]</span> Trial 19 finished with value: 0.8632396747753758 and parameters: {'classifier': 'SVC', 'c': 0.02024212363284256}. Best is trial 13 with value: 0.8796797996229905.
<span class="ansi-green-fg">[I 2020-12-04 13:30:57,113]</span> Trial 20 finished with value: 0.8250796650536528 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 15, 'n_estimator': 100}. Best is trial 13 with value: 0.8796797996229905.
<span class="ansi-green-fg">[I 2020-12-04 13:30:58,166]</span> Trial 21 finished with value: 0.8745198428047513 and parameters: {'classifier': 'SVC', 'c': 2.8141429666154796}. Best is trial 13 with value: 0.8796797996229905.
<span class="ansi-green-fg">[I 2020-12-04 13:30:58,588]</span> Trial 22 finished with value: 0.8779197484194065 and parameters: {'classifier': 'SVC', 'c': 0.06403159117739417}. Best is trial 13 with value: 0.8796797996229905.
<span class="ansi-green-fg">[I 2020-12-04 13:31:06,631]</span> Trial 23 finished with value: 0.8662398619774884 and parameters: {'classifier': 'SVC', 'c': 322.3759012574662}. Best is trial 13 with value: 0.8796797996229905.
<span class="ansi-green-fg">[I 2020-12-04 13:31:06,967]</span> Trial 24 finished with value: 0.8316396010772037 and parameters: {'classifier': 'SVC', 'c': 6.562613218751375e-05}. Best is trial 13 with value: 0.8796797996229905.
<span class="ansi-green-fg">[I 2020-12-04 13:31:19,668]</span> Trial 25 finished with value: 0.8295197706636367 and parameters: {'classifier': 'LogReg', 'loss': 'l2', 'rf_max_depth': 8, 'n_estimator': 300}. Best is trial 13 with value: 0.8796797996229905.
<span class="ansi-green-fg">[I 2020-12-04 13:31:20,207]</span> Trial 26 finished with value: 0.8853198188402698 and parameters: {'classifier': 'SVC', 'c': 0.46782324148727283}. Best is trial 26 with value: 0.8853198188402698.
<span class="ansi-green-fg">[I 2020-12-04 13:31:20,442]</span> Trial 27 finished with value: 0.820759593042709 and parameters: {'classifier': 'SVC', 'c': 5.226694743474181e-08}. Best is trial 26 with value: 0.8853198188402698.
<span class="ansi-green-fg">[I 2020-12-04 13:31:20,802]</span> Trial 28 finished with value: 0.8414796443069626 and parameters: {'classifier': 'SVC', 'c': 0.003193234097835833}. Best is trial 26 with value: 0.8853198188402698.
<span class="ansi-green-fg">[I 2020-12-04 13:31:32,070]</span> Trial 29 finished with value: 0.8235597290462292 and parameters: {'classifier': 'LogReg', 'loss': 'elasticnet', 'rf_max_depth': 3, 'n_estimator': 500}. Best is trial 26 with value: 0.8853198188402698.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 1.49 s, sys: 136 ms, total: 1.62 s
Wall time: 2min 44s
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">studySK</span><span class="o">.</span><span class="n">best_params</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{'c': 0.46782324148727283, 'classifier': 'SVC'}</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">svc</span><span class="o">=</span><span class="n">LinearSVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">studySK</span><span class="o">.</span><span class="n">best_params</span><span class="p">[</span><span class="s1">'c'</span><span class="p">])</span>
<span class="n">svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">trainDf</span><span class="p">[</span><span class="s1">'Label'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>LinearSVC(C=0.46782324148727283, class_weight=None, dual=True,
          fit_intercept=True, intercept_scaling=1, loss='squared_hinge',
          max_iter=1000, multi_class='ovr', penalty='l2', random_state=None,
          tol=0.0001, verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">),</span><span class="n">testDf</span><span class="p">[</span><span class="s1">'Label'</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

         0.0       0.88      0.87      0.87     12646
         1.0       0.87      0.88      0.87     12354

    accuracy                           0.87     25000
   macro avg       0.87      0.87      0.87     25000
weighted avg       0.87      0.87      0.87     25000

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The BOW models performs well infact one could use the unsupervised data also for TFIDF which gives us good result. Another imporvement could have been using truncated SVD in the pipeline to make it even more easier for models to fit. Since fitting models was not time taking much we could do an exhaustive search for hyperparameters and find good one for these models.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="FAST-TEXT">
<a class="anchor" href="#FAST-TEXT" aria-hidden="true"><span class="octicon octicon-link"></span></a>FAST TEXT<a class="anchor-link" href="#FAST-TEXT"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Fast text expect inout data to be of a certain form hence we need to preprocess our data accordingly. It is a method for cpu utilisation and seems to be quite robust and compact</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install fasttext
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting fasttext
  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 3.8MB/s 
Requirement already satisfied: pybind11&gt;=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.6.1)
Requirement already satisfied: setuptools&gt;=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (50.3.2)
Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.5)
Building wheels for collected packages: fasttext
  Building wheel for fasttext (setup.py) ... done
  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3038678 sha256=402134e5718634d7967fe276865bdb4c7c97360bb7bb1ebc28bc25e836f1e89c
  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592
Successfully built fasttext
Installing collected packages: fasttext
Successfully installed fasttext-0.9.2
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We clean minimally for deep learning models.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">=</span>  <span class="n">trainDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="s1">'html.parser'</span><span class="p">)</span><span class="o">.</span><span class="n">get_text</span><span class="p">())</span>
<span class="n">trainDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span> <span class="o">=</span> <span class="n">trainDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
<span class="n">trainDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span> <span class="o">=</span> <span class="n">trainDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">alpha_num</span><span class="p">)</span>
<span class="n">trainDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span> <span class="o">=</span> <span class="n">trainDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">replace_num</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">testDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">=</span>  <span class="n">testDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="s1">'html.parser'</span><span class="p">)</span><span class="o">.</span><span class="n">get_text</span><span class="p">())</span>
<span class="n">testDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span> <span class="o">=</span> <span class="n">testDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
<span class="n">testDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span> <span class="o">=</span> <span class="n">testDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">alpha_num</span><span class="p">)</span>
<span class="n">testDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span> <span class="o">=</span> <span class="n">testDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">replace_num</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">makeFastextData</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">dataset</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'fasttext_input_imdb_'</span><span class="o">+</span><span class="n">dataset</span> <span class="o">+</span><span class="s1">'.txt'</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">text</span><span class="p">,</span><span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">],</span><span class="n">data</span><span class="p">[</span><span class="s1">'Label'</span><span class="p">]):</span>
            <span class="n">f</span><span class="o">.</span><span class="n">writelines</span><span class="p">(</span><span class="sa">f</span><span class="s1">'__label__</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">makeFastextData</span><span class="p">(</span><span class="n">trainDf</span><span class="p">,</span><span class="s1">'train'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">makeFastextData</span><span class="p">(</span><span class="n">testDf</span><span class="p">,</span><span class="s1">'test'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>wc fasttext_input_imdb_train.txt
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>   25000  5744161 32330565 fasttext_input_imdb_train.txt
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>wc fasttext_input_imdb_test.txt
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>   25000  5615443 31564214 fasttext_input_imdb_test.txt
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Some extra preprocessing</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>cat fasttext_input_imdb_train.txt <span class="p">|</span> sed -e <span class="s2">"s/\([.\!?,'/()]\)/ \1 /g"</span> <span class="p">|</span> tr <span class="s2">"[:upper:]"</span> <span class="s2">"[:lower:]"</span> &gt; fasttext_input_imdb_train_proc.txt
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>cat fasttext_input_imdb_test.txt <span class="p">|</span> sed -e <span class="s2">"s/\([.\!?,'/()]\)/ \1 /g"</span> <span class="p">|</span> tr <span class="s2">"[:upper:]"</span> <span class="s2">"[:lower:]"</span> &gt; fasttext_input_imdb_test_proc.txt
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>head -n <span class="m">24000</span> fasttext_input_imdb_train_proc.txt &gt; imdb_train.bin
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>tail -n <span class="m">1000</span> fasttext_input_imdb_train_proc.txt &gt; imdb_valid.bin
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>head -n <span class="m">25000</span> fasttext_input_imdb_test_proc.txt &gt; imdb_test.bin
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">fasttext</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we use autotune funcionality of fasttext to find a perfect model for us by doing changes based on validation data. limited the duration to 100 for fast execution and also limit the size of the output model. For faster convergence we use hierarchical softmax as the loss.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">fasttext</span><span class="o">.</span><span class="n">train_supervised</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="s1">'imdb_train.bin'</span><span class="p">,</span><span class="n">autotuneValidationFile</span><span class="o">=</span><span class="s1">'imdb_valid.bin'</span><span class="p">,</span><span class="n">autotuneModelSize</span><span class="o">=</span><span class="s2">"2M"</span><span class="p">,</span> <span class="n">autotuneDuration</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">'hs'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 2min 22s, sys: 31.1 ms, total: 2min 22s
Wall time: 2min 22s
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_</span><span class="p">,</span><span class="n">precision</span><span class="p">,</span><span class="n">recall</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="s1">'imdb_test.bin'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Precision:'</span><span class="p">,</span><span class="n">precision</span><span class="p">,</span><span class="s1">'recall:'</span><span class="p">,</span><span class="n">recall</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Precision: 0.87892 recall: 0.87892
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>saved the model here in compact quantized form so that it can be use later.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">quantize</span><span class="p">(</span><span class="n">retrain</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model_filename.ftz"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Fast text is a very good easy to use and very well engineered solution which give great results too. i tried to search for a way to learn representation present in text and use it as a start for classification but could not find that bridge although one can learn the representation easily by using function learn_unsupervised</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Sequence-RNN">
<a class="anchor" href="#Sequence-RNN" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sequence RNN<a class="anchor-link" href="#Sequence-RNN"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>we use keras tokenizer trained on the unsupervised+training test and then transform test data using it as well as train. i experiment with 2 layer lstm structure for which we select hyperparameters using optuna again. used a 2 layer lstm structure for which we find optimal hyperparameter due to resource content and time needed by models to run we dont choose many trials.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.text</span> <span class="kn">import</span> <span class="n">Tokenizer</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span>
<span class="n">t</span><span class="o">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="n">trainPlusUnsupDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainText</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">trainDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">testText</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">testDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainTextPadded</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">trainText</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">'int32'</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">'post'</span><span class="p">,</span> <span class="n">truncating</span><span class="o">=</span><span class="s1">'post'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">testTextPadded</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">testText</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">'int32'</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">'post'</span><span class="p">,</span> <span class="n">truncating</span><span class="o">=</span><span class="s1">'post'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span><span class="p">,</span><span class="n">Embedding</span><span class="p">,</span><span class="n">GRU</span><span class="p">,</span><span class="n">Dense</span><span class="p">,</span><span class="n">Input</span><span class="p">,</span><span class="n">Dropout</span><span class="p">,</span><span class="n">Bidirectional</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">RMSprop</span><span class="p">,</span><span class="n">Adam</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">trainTextPadded</span><span class="p">,</span> <span class="n">trainDf</span><span class="p">[</span><span class="s1">'Label'</span><span class="p">],</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="k">def</span> <span class="nf">objectiveLSTM</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="n">inpt</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">300</span><span class="p">,))</span>
    <span class="n">embedding</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span><span class="n">output_dim</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="s2">"embedding"</span><span class="p">,</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">]),</span> <span class="n">input_length</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">mask_zero</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span><span class="n">inpt</span><span class="p">)</span>
    <span class="n">LSTM1</span><span class="o">=</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="s2">"units1"</span><span class="p">,</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">256</span><span class="p">]),</span><span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))(</span><span class="n">embedding</span><span class="p">)</span>
    <span class="n">dropout</span><span class="o">=</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_loguniform</span><span class="p">(</span><span class="s1">'dropout'</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="mf">5e-1</span><span class="p">))(</span><span class="n">LSTM1</span><span class="p">)</span>
    <span class="n">LSTM2</span><span class="o">=</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="s2">"units2"</span><span class="p">,</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">128</span><span class="p">]),</span><span class="n">return_sequences</span><span class="o">=</span><span class="kc">False</span><span class="p">))(</span><span class="n">dropout</span><span class="p">)</span>
    <span class="n">output</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">)(</span><span class="n">LSTM2</span><span class="p">)</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Model</span><span class="p">(</span><span class="n">inpt</span><span class="p">,</span><span class="n">output</span><span class="p">)</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_loguniform</span><span class="p">(</span><span class="s1">'lr'</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">accuracy</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">accuracy</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">studyDL</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s1">'minimize'</span><span class="p">)</span>
<span class="n">studyDL</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objectiveLSTM</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre><span class="ansi-green-fg">[I 2020-12-04 15:56:48,108]</span> A new study created in memory with name: no-name-63df6f6a-b44a-48ca-9ae5-105f9e61f3a7
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/10
36/36 [==============================] - 14s 377ms/step - loss: 0.6842 - accuracy: 0.6080 - val_loss: 0.6049 - val_accuracy: 0.6760
Epoch 2/10
36/36 [==============================] - 9s 259ms/step - loss: 0.5117 - accuracy: 0.7650 - val_loss: 0.4550 - val_accuracy: 0.7850
Epoch 3/10
36/36 [==============================] - 9s 259ms/step - loss: 0.3579 - accuracy: 0.8429 - val_loss: 0.5821 - val_accuracy: 0.7550
Epoch 4/10
36/36 [==============================] - 9s 259ms/step - loss: 0.2589 - accuracy: 0.8945 - val_loss: 0.5419 - val_accuracy: 0.7770
Epoch 5/10
36/36 [==============================] - 9s 258ms/step - loss: 0.1753 - accuracy: 0.9327 - val_loss: 0.6102 - val_accuracy: 0.7345
Epoch 6/10
36/36 [==============================] - 9s 259ms/step - loss: 0.1415 - accuracy: 0.9468 - val_loss: 0.5000 - val_accuracy: 0.8165
Epoch 7/10
36/36 [==============================] - 9s 259ms/step - loss: 0.0930 - accuracy: 0.9638 - val_loss: 0.9224 - val_accuracy: 0.6855
Epoch 8/10
36/36 [==============================] - 9s 260ms/step - loss: 0.1016 - accuracy: 0.9628 - val_loss: 0.6156 - val_accuracy: 0.7845
Epoch 9/10
36/36 [==============================] - 9s 258ms/step - loss: 0.0511 - accuracy: 0.9852 - val_loss: 0.5967 - val_accuracy: 0.7960
Epoch 10/10
36/36 [==============================] - 9s 259ms/step - loss: 0.0460 - accuracy: 0.9824 - val_loss: 0.7120 - val_accuracy: 0.8050
157/157 [==============================] - 3s 22ms/step - loss: 0.6811 - accuracy: 0.8076
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre><span class="ansi-green-fg">[I 2020-12-04 15:58:59,365]</span> Trial 0 finished with value: 0.6811148524284363 and parameters: {'embedding': 50, 'units1': 64, 'dropout': 0.22504036672028457, 'units2': 32, 'lr': 0.008674885296861211}. Best is trial 0 with value: 0.6811148524284363.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/10
36/36 [==============================] - 14s 385ms/step - loss: 0.6923 - accuracy: 0.5211 - val_loss: 0.6897 - val_accuracy: 0.5410
Epoch 2/10
36/36 [==============================] - 10s 274ms/step - loss: 0.6286 - accuracy: 0.6923 - val_loss: 0.4985 - val_accuracy: 0.7650
Epoch 3/10
36/36 [==============================] - 10s 274ms/step - loss: 0.4178 - accuracy: 0.8182 - val_loss: 0.4259 - val_accuracy: 0.8110
Epoch 4/10
36/36 [==============================] - 10s 273ms/step - loss: 0.3308 - accuracy: 0.8665 - val_loss: 0.3624 - val_accuracy: 0.8455
Epoch 5/10
36/36 [==============================] - 10s 273ms/step - loss: 0.2694 - accuracy: 0.8977 - val_loss: 0.3391 - val_accuracy: 0.8675
Epoch 6/10
36/36 [==============================] - 10s 272ms/step - loss: 0.2275 - accuracy: 0.9151 - val_loss: 0.3360 - val_accuracy: 0.8775
Epoch 7/10
36/36 [==============================] - 10s 273ms/step - loss: 0.1878 - accuracy: 0.9328 - val_loss: 0.4527 - val_accuracy: 0.8445
Epoch 8/10
36/36 [==============================] - 10s 274ms/step - loss: 0.1630 - accuracy: 0.9429 - val_loss: 0.3379 - val_accuracy: 0.8790
Epoch 9/10
36/36 [==============================] - 10s 273ms/step - loss: 0.1361 - accuracy: 0.9536 - val_loss: 0.3432 - val_accuracy: 0.8775
Epoch 10/10
36/36 [==============================] - 10s 275ms/step - loss: 0.1099 - accuracy: 0.9637 - val_loss: 0.3591 - val_accuracy: 0.8590
157/157 [==============================] - 4s 23ms/step - loss: 0.3803 - accuracy: 0.8502
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre><span class="ansi-green-fg">[I 2020-12-04 16:01:04,098]</span> Trial 1 finished with value: 0.38028624653816223 and parameters: {'embedding': 50, 'units1': 64, 'dropout': 0.3706454194859867, 'units2': 64, 'lr': 0.00016189924268387887}. Best is trial 1 with value: 0.38028624653816223.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/10
36/36 [==============================] - 13s 374ms/step - loss: 0.6136 - accuracy: 0.6732 - val_loss: 0.4087 - val_accuracy: 0.8200
Epoch 2/10
36/36 [==============================] - 10s 274ms/step - loss: 0.3540 - accuracy: 0.8510 - val_loss: 0.4048 - val_accuracy: 0.8260
Epoch 3/10
36/36 [==============================] - 10s 274ms/step - loss: 0.2343 - accuracy: 0.9084 - val_loss: 0.3642 - val_accuracy: 0.8550
Epoch 4/10
36/36 [==============================] - 10s 273ms/step - loss: 0.1784 - accuracy: 0.9336 - val_loss: 0.3657 - val_accuracy: 0.8660
Epoch 5/10
36/36 [==============================] - 10s 273ms/step - loss: 0.1308 - accuracy: 0.9510 - val_loss: 0.4816 - val_accuracy: 0.8545
Epoch 6/10
36/36 [==============================] - 10s 272ms/step - loss: 0.0933 - accuracy: 0.9664 - val_loss: 0.4857 - val_accuracy: 0.7950
Epoch 7/10
36/36 [==============================] - 10s 273ms/step - loss: 0.0546 - accuracy: 0.9820 - val_loss: 0.5534 - val_accuracy: 0.8635
Epoch 8/10
36/36 [==============================] - 10s 274ms/step - loss: 0.0463 - accuracy: 0.9835 - val_loss: 0.5407 - val_accuracy: 0.8580
Epoch 9/10
36/36 [==============================] - 10s 273ms/step - loss: 0.0344 - accuracy: 0.9881 - val_loss: 0.5886 - val_accuracy: 0.8555
Epoch 10/10
36/36 [==============================] - 10s 274ms/step - loss: 0.0321 - accuracy: 0.9884 - val_loss: 0.5884 - val_accuracy: 0.8580
157/157 [==============================] - 4s 22ms/step - loss: 0.5836 - accuracy: 0.8582
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre><span class="ansi-green-fg">[I 2020-12-04 16:03:08,472]</span> Trial 2 finished with value: 0.5836058855056763 and parameters: {'embedding': 50, 'units1': 64, 'dropout': 0.1275607257989057, 'units2': 64, 'lr': 0.0020301932674781486}. Best is trial 1 with value: 0.38028624653816223.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/10
36/36 [==============================] - 19s 514ms/step - loss: 0.6922 - accuracy: 0.5332 - val_loss: 0.6908 - val_accuracy: 0.5860
Epoch 2/10
36/36 [==============================] - 15s 415ms/step - loss: 0.6754 - accuracy: 0.6570 - val_loss: 0.5943 - val_accuracy: 0.7025
Epoch 3/10
36/36 [==============================] - 15s 414ms/step - loss: 0.5075 - accuracy: 0.7626 - val_loss: 0.4557 - val_accuracy: 0.7970
Epoch 4/10
36/36 [==============================] - 15s 415ms/step - loss: 0.3980 - accuracy: 0.8305 - val_loss: 0.4485 - val_accuracy: 0.8050
Epoch 5/10
36/36 [==============================] - 15s 412ms/step - loss: 0.3251 - accuracy: 0.8691 - val_loss: 0.4432 - val_accuracy: 0.8120
Epoch 6/10
36/36 [==============================] - 15s 417ms/step - loss: 0.2710 - accuracy: 0.8966 - val_loss: 0.3585 - val_accuracy: 0.8470
Epoch 7/10
36/36 [==============================] - 15s 415ms/step - loss: 0.2351 - accuracy: 0.9135 - val_loss: 0.3566 - val_accuracy: 0.8560
Epoch 8/10
36/36 [==============================] - 15s 414ms/step - loss: 0.1995 - accuracy: 0.9301 - val_loss: 0.4250 - val_accuracy: 0.8350
Epoch 9/10
36/36 [==============================] - 15s 415ms/step - loss: 0.1723 - accuracy: 0.9423 - val_loss: 0.3400 - val_accuracy: 0.8590
Epoch 10/10
36/36 [==============================] - 15s 415ms/step - loss: 0.1463 - accuracy: 0.9514 - val_loss: 0.4038 - val_accuracy: 0.8635
157/157 [==============================] - 4s 24ms/step - loss: 0.4163 - accuracy: 0.8548
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre><span class="ansi-green-fg">[I 2020-12-04 16:06:05,257]</span> Trial 3 finished with value: 0.4163428843021393 and parameters: {'embedding': 100, 'units1': 128, 'dropout': 0.2709290810082003, 'units2': 64, 'lr': 9.041356047814194e-05}. Best is trial 1 with value: 0.38028624653816223.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/10
36/36 [==============================] - 16s 451ms/step - loss: 0.6749 - accuracy: 0.6149 - val_loss: 0.5397 - val_accuracy: 0.7425
Epoch 2/10
36/36 [==============================] - 12s 338ms/step - loss: 0.4680 - accuracy: 0.7923 - val_loss: 0.7116 - val_accuracy: 0.6825
Epoch 3/10
36/36 [==============================] - 12s 338ms/step - loss: 0.4096 - accuracy: 0.8179 - val_loss: 0.4056 - val_accuracy: 0.8115
Epoch 4/10
36/36 [==============================] - 12s 338ms/step - loss: 0.2572 - accuracy: 0.8961 - val_loss: 0.4227 - val_accuracy: 0.8235
Epoch 5/10
36/36 [==============================] - 12s 338ms/step - loss: 0.1988 - accuracy: 0.9237 - val_loss: 0.7829 - val_accuracy: 0.7080
Epoch 6/10
36/36 [==============================] - 12s 338ms/step - loss: 0.1731 - accuracy: 0.9328 - val_loss: 0.4729 - val_accuracy: 0.8015
Epoch 7/10
36/36 [==============================] - 12s 337ms/step - loss: 0.1406 - accuracy: 0.9492 - val_loss: 0.8127 - val_accuracy: 0.7070
Epoch 8/10
36/36 [==============================] - 12s 336ms/step - loss: 0.1125 - accuracy: 0.9569 - val_loss: 0.5266 - val_accuracy: 0.7965
Epoch 9/10
36/36 [==============================] - 12s 338ms/step - loss: 0.0567 - accuracy: 0.9808 - val_loss: 0.5345 - val_accuracy: 0.8400
Epoch 10/10
36/36 [==============================] - 12s 337ms/step - loss: 0.0791 - accuracy: 0.9735 - val_loss: 1.2125 - val_accuracy: 0.7055
157/157 [==============================] - 4s 23ms/step - loss: 1.2458 - accuracy: 0.7060
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre><span class="ansi-green-fg">[I 2020-12-04 16:08:33,779]</span> Trial 4 finished with value: 1.2457996606826782 and parameters: {'embedding': 50, 'units1': 128, 'dropout': 0.3363530997614701, 'units2': 32, 'lr': 0.003724474987378308}. Best is trial 1 with value: 0.38028624653816223.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 7min 47s, sys: 28.5 s, total: 8min 16s
Wall time: 11min 45s
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">studyDL</span><span class="o">.</span><span class="n">best_params</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{'dropout': 0.3706454194859867,
 'embedding': 50,
 'lr': 0.00016189924268387887,
 'units1': 64,
 'units2': 64}</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">studyDL</span><span class="o">.</span><span class="n">best_trial</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>FrozenTrial(number=1, value=0.38028624653816223, datetime_start=datetime.datetime(2020, 12, 4, 15, 58, 59, 366599), datetime_complete=datetime.datetime(2020, 12, 4, 16, 1, 4, 97783), params={'embedding': 50, 'units1': 64, 'dropout': 0.3706454194859867, 'units2': 64, 'lr': 0.00016189924268387887}, distributions={'embedding': CategoricalDistribution(choices=(50, 100)), 'units1': CategoricalDistribution(choices=(64, 128, 256)), 'dropout': LogUniformDistribution(high=0.5, low=0.1), 'units2': CategoricalDistribution(choices=(32, 64, 128)), 'lr': LogUniformDistribution(high=0.01, low=1e-05)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=1, state=TrialState.COMPLETE)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So for using pretrained embedding we used here glove and fasttext embeddign which initiliases the weights of our embedding layer and we set it trainable to false</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>wget http://nlp.stanford.edu/data/glove.twitter.27B.zip
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>--2020-12-04 14:32:47--  http://nlp.stanford.edu/data/glove.twitter.27B.zip
Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140
Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]
--2020-12-04 14:32:48--  https://nlp.stanford.edu/data/glove.twitter.27B.zip
Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.
HTTP request sent, awaiting response... 301 Moved Permanently
Location: http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]
--2020-12-04 14:32:48--  http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip
Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22
Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1520408563 (1.4G) [application/zip]
Saving to: â€˜glove.twitter.27B.zipâ€™

glove.twitter.27B.z 100%[===================&gt;]   1.42G  2.18MB/s    in 11m 43s 

2020-12-04 14:44:31 (2.06 MB/s) - â€˜glove.twitter.27B.zipâ€™ saved [1520408563/1520408563]

</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>unzip glove.twitter.27B.zip
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Archive:  glove.twitter.27B.zip
  inflating: glove.twitter.27B.25d.txt  
  inflating: glove.twitter.27B.50d.txt  
replace glove.twitter.27B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y
  inflating: glove.twitter.27B.100d.txt  
  inflating: glove.twitter.27B.200d.txt  
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>--2020-12-04 14:48:01--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip
Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...
Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 681808098 (650M) [application/zip]
Saving to: â€˜wiki-news-300d-1M.vec.zipâ€™

wiki-news-300d-1M.v 100%[===================&gt;] 650.22M  12.5MB/s    in 53s     

2020-12-04 14:48:56 (12.2 MB/s) - â€˜wiki-news-300d-1M.vec.zipâ€™ saved [681808098/681808098]

</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>unzip wiki-news-300d-1M.vec.zip
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Archive:  wiki-news-300d-1M.vec.zip
  inflating: wiki-news-300d-1M.vec   
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">embeddingWeights</span><span class="p">(</span><span class="n">embeddingType</span><span class="p">,</span><span class="n">word_index</span><span class="p">):</span>
  <span class="n">embeddings_index</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="k">if</span><span class="p">(</span><span class="n">embeddingType</span><span class="o">==</span><span class="s1">'glove'</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'glove.twitter.27B.50d.txt'</span><span class="p">)</span>
    <span class="n">EMBEDDING_DIM</span><span class="o">=</span><span class="mi">50</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'wiki-news-300d-1M.vec'</span><span class="p">)</span>
    <span class="n">EMBEDDING_DIM</span><span class="o">=</span><span class="mi">300</span>
  <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
      <span class="n">values</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
      <span class="n">word</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">'float32'</span><span class="p">)</span>
      <span class="n">embeddings_index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">coefs</span>
  <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

  <span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">EMBEDDING_DIM</span><span class="p">))</span>
  <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">word_index</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="n">embedding_vector</span> <span class="o">=</span> <span class="n">embeddings_index</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">embedding_vector</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
          <span class="n">embedding_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">embedding_vector</span>
  <span class="k">return</span> <span class="n">embedding_matrix</span><span class="p">,</span><span class="n">EMBEDDING_DIM</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="n">glove</span><span class="p">,</span><span class="n">emd</span><span class="o">=</span><span class="n">embeddingWeights</span><span class="p">(</span><span class="s1">'glove'</span><span class="p">,</span><span class="n">t</span><span class="o">.</span><span class="n">word_index</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 17.1 s, sys: 958 ms, total: 18 s
Wall time: 18 s
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="n">fasttext</span><span class="p">,</span><span class="n">embd</span><span class="o">=</span><span class="n">embeddingWeights</span><span class="p">(</span><span class="s1">'fasttext'</span><span class="p">,</span><span class="n">t</span><span class="o">.</span><span class="n">word_index</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 1min 5s, sys: 3.01 s, total: 1min 8s
Wall time: 1min 8s
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">makeLSTM</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span><span class="n">dropout</span><span class="p">,</span><span class="n">lr</span><span class="p">,</span><span class="n">units1</span><span class="p">,</span><span class="n">units2</span><span class="p">,</span><span class="n">usePretrained</span><span class="p">,</span><span class="n">embedding_matrix</span><span class="p">):</span>
    <span class="n">inpt</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">300</span><span class="p">,))</span>
    <span class="k">if</span><span class="p">(</span><span class="ow">not</span> <span class="n">usePretrained</span><span class="p">):</span>
      <span class="n">embedding</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span><span class="n">output_dim</span><span class="o">=</span><span class="n">embedding</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">mask_zero</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span><span class="n">inpt</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">embedding</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span><span class="n">output_dim</span><span class="o">=</span><span class="n">embedding</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">mask_zero</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="n">embedding_matrix</span><span class="p">],</span><span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)(</span><span class="n">inpt</span><span class="p">)</span>

    <span class="n">LSTM1</span><span class="o">=</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">units1</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))(</span><span class="n">embedding</span><span class="p">)</span>
    <span class="n">drop</span><span class="o">=</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="n">dropout</span><span class="p">)(</span><span class="n">LSTM1</span><span class="p">)</span>
    <span class="n">LSTM2</span><span class="o">=</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">units2</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="kc">False</span><span class="p">))(</span><span class="n">drop</span><span class="p">)</span>
    <span class="n">output</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">)(</span><span class="n">LSTM2</span><span class="p">)</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Model</span><span class="p">(</span><span class="n">inpt</span><span class="p">,</span><span class="n">output</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainTextPadded</span><span class="p">,</span><span class="n">trainDf</span><span class="p">[</span><span class="s1">'Label'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we use the params we found using optuna for lstm based models.</p>
<p>{'dropout': 0.3706454194859867,
 'embedding': 50,
 'lr': 0.00016189924268387887,
 'units1': 64,
 'units2': 64}</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">modelLSTM</span><span class="o">=</span><span class="n">makeLSTM</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="mf">0.37</span><span class="p">,</span><span class="mf">0.00016</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="kc">False</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/10
44/44 [==============================] - 16s 370ms/step - loss: 0.6898 - accuracy: 0.5742 - val_loss: 0.6753 - val_accuracy: 0.6944
Epoch 2/10
44/44 [==============================] - 12s 283ms/step - loss: 0.5134 - accuracy: 0.7696 - val_loss: 0.4666 - val_accuracy: 0.7824
Epoch 3/10
44/44 [==============================] - 12s 283ms/step - loss: 0.3553 - accuracy: 0.8519 - val_loss: 0.4220 - val_accuracy: 0.8084
Epoch 4/10
44/44 [==============================] - 12s 283ms/step - loss: 0.2882 - accuracy: 0.8859 - val_loss: 0.3599 - val_accuracy: 0.8428
Epoch 5/10
44/44 [==============================] - 12s 282ms/step - loss: 0.2342 - accuracy: 0.9120 - val_loss: 0.3435 - val_accuracy: 0.8568
Epoch 6/10
44/44 [==============================] - 12s 284ms/step - loss: 0.1997 - accuracy: 0.9261 - val_loss: 0.3219 - val_accuracy: 0.8772
Epoch 7/10
44/44 [==============================] - 12s 284ms/step - loss: 0.1648 - accuracy: 0.9422 - val_loss: 0.3309 - val_accuracy: 0.8776
Epoch 8/10
44/44 [==============================] - 12s 283ms/step - loss: 0.1391 - accuracy: 0.9528 - val_loss: 0.3400 - val_accuracy: 0.8784
Epoch 9/10
44/44 [==============================] - 12s 283ms/step - loss: 0.1175 - accuracy: 0.9609 - val_loss: 0.4453 - val_accuracy: 0.8628
Epoch 10/10
44/44 [==============================] - 12s 283ms/step - loss: 0.0993 - accuracy: 0.9683 - val_loss: 0.3774 - val_accuracy: 0.8764
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">modelLSTM</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testTextPadded</span><span class="p">,</span><span class="n">testDf</span><span class="p">[</span><span class="s1">'Label'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>782/782 [==============================] - 18s 22ms/step - loss: 0.4298 - accuracy: 0.8522
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[0.42976242303848267, 0.8522400259971619]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">modelLSTMGlove</span><span class="o">=</span><span class="n">makeLSTM</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="mf">0.37</span><span class="p">,</span><span class="mf">0.00016</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="kc">True</span><span class="p">,</span><span class="n">glove</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/10
44/44 [==============================] - 14s 317ms/step - loss: 0.6733 - accuracy: 0.5908 - val_loss: 0.6399 - val_accuracy: 0.6396
Epoch 2/10
44/44 [==============================] - 10s 236ms/step - loss: 0.5996 - accuracy: 0.6828 - val_loss: 0.5484 - val_accuracy: 0.7224
Epoch 3/10
44/44 [==============================] - 10s 235ms/step - loss: 0.5605 - accuracy: 0.7183 - val_loss: 0.5308 - val_accuracy: 0.7412
Epoch 4/10
44/44 [==============================] - 10s 236ms/step - loss: 0.5487 - accuracy: 0.7259 - val_loss: 0.5198 - val_accuracy: 0.7500
Epoch 5/10
44/44 [==============================] - 10s 236ms/step - loss: 0.5344 - accuracy: 0.7363 - val_loss: 0.5922 - val_accuracy: 0.6804
Epoch 6/10
44/44 [==============================] - 10s 236ms/step - loss: 0.5264 - accuracy: 0.7410 - val_loss: 0.5494 - val_accuracy: 0.7336
Epoch 7/10
44/44 [==============================] - 10s 236ms/step - loss: 0.5217 - accuracy: 0.7460 - val_loss: 0.5292 - val_accuracy: 0.7356
Epoch 8/10
44/44 [==============================] - 10s 236ms/step - loss: 0.5115 - accuracy: 0.7504 - val_loss: 0.5728 - val_accuracy: 0.7120
Epoch 9/10
44/44 [==============================] - 10s 235ms/step - loss: 0.5113 - accuracy: 0.7527 - val_loss: 0.4952 - val_accuracy: 0.7668
Epoch 10/10
44/44 [==============================] - 10s 236ms/step - loss: 0.5005 - accuracy: 0.7584 - val_loss: 0.4992 - val_accuracy: 0.7672
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">modelLSTMGlove</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testTextPadded</span><span class="p">,</span><span class="n">testDf</span><span class="p">[</span><span class="s1">'Label'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>782/782 [==============================] - 18s 23ms/step - loss: 0.5002 - accuracy: 0.7660
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[0.5001837015151978, 0.766040027141571]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Keeping all the parameters same as that of simple lstm(flexible embedding layers)vs glove embedding layer we see the drop in performance which is quite explainable by the fact that text used train glove is different from the text here (even tho its text from twitter). Moreover can also see that the model takes more time to fit (train accuracy) but this could improve with more epoch or using high dimensional embedding of glove. could also have more complicated achitechtures and more intensive hyperparameter search but for now due to resource contraint we limit ourselves.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since the embedding size offered by fasttext is bigger it might be good idea to use more units of lstm.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">modelLSTMfasttext</span><span class="o">=</span><span class="n">makeLSTM</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span><span class="mf">0.37</span><span class="p">,</span><span class="mf">0.00016</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="kc">True</span><span class="p">,</span><span class="n">fasttext</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/10
44/44 [==============================] - 23s 517ms/step - loss: 0.6563 - accuracy: 0.6223 - val_loss: 0.7108 - val_accuracy: 0.5560
Epoch 2/10
44/44 [==============================] - 19s 439ms/step - loss: 0.5511 - accuracy: 0.7198 - val_loss: 0.4735 - val_accuracy: 0.7880
Epoch 3/10
44/44 [==============================] - 19s 438ms/step - loss: 0.4919 - accuracy: 0.7630 - val_loss: 0.4836 - val_accuracy: 0.7688
Epoch 4/10
44/44 [==============================] - 19s 437ms/step - loss: 0.4570 - accuracy: 0.7896 - val_loss: 0.5255 - val_accuracy: 0.7464
Epoch 5/10
44/44 [==============================] - 19s 438ms/step - loss: 0.4453 - accuracy: 0.7941 - val_loss: 0.5087 - val_accuracy: 0.7656
Epoch 6/10
44/44 [==============================] - 19s 437ms/step - loss: 0.4302 - accuracy: 0.8054 - val_loss: 0.4884 - val_accuracy: 0.7596
Epoch 7/10
44/44 [==============================] - 19s 436ms/step - loss: 0.4207 - accuracy: 0.8088 - val_loss: 0.4005 - val_accuracy: 0.8200
Epoch 8/10
44/44 [==============================] - 19s 438ms/step - loss: 0.4111 - accuracy: 0.8140 - val_loss: 0.3988 - val_accuracy: 0.8300
Epoch 9/10
44/44 [==============================] - 19s 438ms/step - loss: 0.3991 - accuracy: 0.8220 - val_loss: 0.3714 - val_accuracy: 0.8384
Epoch 10/10
44/44 [==============================] - 19s 437ms/step - loss: 0.3999 - accuracy: 0.8192 - val_loss: 0.3683 - val_accuracy: 0.8460
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">modelLSTMfasttext</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testTextPadded</span><span class="p">,</span><span class="n">testDf</span><span class="p">[</span><span class="s1">'Label'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>782/782 [==============================] - 21s 27ms/step - loss: 0.3705 - accuracy: 0.8396
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[0.37046363949775696, 0.8396000266075134]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we get reasonable accuracy but we had to use a slightly bigger model. But since its a bigger size vectors it can accomodate somehow. But we can see still wiki news contains corpus which is different from casual commenting on imdb by people.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>contrasting performance of deep learning models with bag of words (fits faster to data aswell) model its interesting to notice that maybe indivisual words might play more role in determing the sentiment as compared to the full sequential structure. but one cannot say that with full certainity since didnt train our models for long enough neither explored more trials of hyperparameters.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="BERT-BASED">
<a class="anchor" href="#BERT-BASED" aria-hidden="true"><span class="octicon octicon-link"></span></a>BERT BASED<a class="anchor-link" href="#BERT-BASED"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we try 2 variants of bert based models first by using distil bert from hugging face an then using ktrain to train the bigger bert.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install transformers
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting transformers
  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.4MB 5.6MB/s 
Collecting sacremoses
  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 19.9MB/s 
Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)
Collecting tokenizers==0.9.4
  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 28.2MB/s 
Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)
Requirement already satisfied: tqdm&gt;=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)
Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)
Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)
Requirement already satisfied: dataclasses; python_version &lt; "3.7" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)
Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses-&gt;transformers) (1.15.0)
Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses-&gt;transformers) (7.1.2)
Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses-&gt;transformers) (0.17.0)
Requirement already satisfied: pyparsing&gt;=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging-&gt;transformers) (2.4.7)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;transformers) (2.10)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;transformers) (1.24.3)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;transformers) (2020.11.8)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;transformers) (3.0.4)
Building wheels for collected packages: sacremoses
  Building wheel for sacremoses (setup.py) ... done
  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=a1ec9e5910bcec29fdd40a087b5167a0a7839887e10711dce208e8319dfc82e2
  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45
Successfully built sacremoses
Installing collected packages: sacremoses, tokenizers, transformers
Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DistilBertTokenizerFast</span><span class="p">,</span> <span class="n">TFDistilBertModel</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We almost used unprocessed data due to the nature of bert tokenizer and also we set do lower case to true which convert data to lower case since we use distilbert base uncased</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">DistilBertTokenizerFast</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'distilbert-base-uncased'</span><span class="p">,</span> <span class="n">do_lower_case</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bert</span> <span class="o">=</span> <span class="n">TFDistilBertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'distilbert-base-uncased'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']
- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bert</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: "tf_distil_bert_model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
distilbert (TFDistilBertMain multiple                  66362880  
=================================================================
Total params: 66,362,880
Trainable params: 66,362,880
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For tokenisation we use fast encoder batch for distil bert which works very fast and automatically adds special tokens and does padding and truncation according to the max length.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">fast_encode</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">chunk_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">512</span><span class="p">):</span>
    <span class="n">all_ids</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">texts</span><span class="p">),</span> <span class="n">chunk_size</span><span class="p">)):</span>
        <span class="n">text_chunk</span> <span class="o">=</span> <span class="n">texts</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">chunk_size</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">encs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_encode_plus</span><span class="p">(</span><span class="n">text_chunk</span><span class="p">,</span><span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">max_length</span><span class="o">=</span><span class="n">maxlen</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">all_ids</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">encs</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">all_ids</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x_train</span> <span class="o">=</span> <span class="n">fast_encode</span><span class="p">(</span><span class="n">trainDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">),</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="n">x_train</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x_test</span> <span class="o">=</span> <span class="n">fast_encode</span><span class="p">(</span><span class="n">testDf</span><span class="p">[</span><span class="s1">'Text'</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">),</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="n">x_test</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_train</span> <span class="o">=</span> <span class="n">trainDf</span><span class="p">[</span><span class="s1">'Label'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">testDf</span><span class="p">[</span><span class="s1">'Label'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamWeightDecay</span><span class="p">,</span><span class="n">get_cosine_schedule_with_warmup</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">modelDBERT</span><span class="p">():</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">300</span><span class="p">,),</span><span class="n">dtype</span><span class="o">=</span><span class="s1">'int32'</span><span class="p">)</span>
    <span class="n">bert</span><span class="o">.</span><span class="n">trainable</span><span class="o">=</span><span class="kc">True</span>
    <span class="n">bertOp</span> <span class="o">=</span> <span class="n">bert</span><span class="p">(</span><span class="nb">input</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">cls_token</span> <span class="o">=</span> <span class="n">bertOp</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">dropout</span><span class="o">=</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)(</span><span class="n">cls_token</span><span class="p">)</span>
    <span class="n">dense1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">)(</span><span class="n">dropout</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">)(</span><span class="n">dense1</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">3e-5</span><span class="p">),</span> <span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we just add a bit of dropout to somehow avoid overfiting and a dense layer to fine tune.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">modelbert</span><span class="o">=</span><span class="n">modelDBERT</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">modelbert</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: "functional_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 300)]             0         
_________________________________________________________________
tf_distil_bert_model (TFDist multiple                  66362880  
_________________________________________________________________
tf_op_layer_strided_slice_2  [(None, 768)]             0         
_________________________________________________________________
dropout_21 (Dropout)         (None, 768)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 128)               98432     
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 129       
=================================================================
Total params: 66,461,441
Trainable params: 66,461,441
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">modelbert</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:Model was constructed with shape (None, 300) for input Tensor("input_3:0", shape=(None, 300), dtype=int32), but it was called on an input with incompatible shape (None, 400).
WARNING:tensorflow:Model was constructed with shape (None, 300) for input Tensor("input_3:0", shape=(None, 300), dtype=int32), but it was called on an input with incompatible shape (None, 400).
1407/1407 [==============================] - ETA: 0s - loss: 0.2798 - accuracy: 0.8800WARNING:tensorflow:Model was constructed with shape (None, 300) for input Tensor("input_3:0", shape=(None, 300), dtype=int32), but it was called on an input with incompatible shape (None, 400).
1407/1407 [==============================] - 587s 418ms/step - loss: 0.2798 - accuracy: 0.8800 - val_loss: 0.1992 - val_accuracy: 0.9228
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tensorflow.python.keras.callbacks.History at 0x7f1180c0efd0&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">modelbert</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>782/782 [==============================] - 196s 250ms/step - loss: 0.1960 - accuracy: 0.9227
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[0.19601084291934967, 0.9226800203323364]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Accuracy wise we get the best results for bert. But one thing which i noticed was that pure fine tuning (freezing the bert layer) and tuning extra added layers doesnt work very well. what works is we update the whole model with a small learning rate so that the weights of bert are not disturbed much</p>

</div>
</div>
</div>
</div>

<script type="application/vnd.jupyter.widget-state+json">
{"0a2936c4a15a429a9db203e1e618705a": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": "initial"}}, "0ce0e1cd79a245f1b08a42f072ba7ccb": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "100%", "description_tooltip": null, "layout": "IPY_MODEL_d5a6f36eb4e849bfb1ab700ae09e404e", "max": 98, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_d065e050632946c2848a7d2adc851dfd", "value": 98}}, "110b4276cae944ab971edf5325fd4cca": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "192e47ef101f466caaf27f1746a2c220": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "1fad94ebb7d34d519b541460d0fc2cb2": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_e526a70702ef4c4c9c67389891ba5309", "placeholder": "\u200b", "style": "IPY_MODEL_65ee33631bda4d579be3b5215ff13aff", "value": " 98/98 [00:39&lt;00:00,  2.46it/s]"}}, "22534a55b7e545ae8e71b6d0cf0b11f6": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "24a58800efe5498296f2e0380c459196": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "26434913a55c4bda95863b72bb03c6f4": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "2c7f8d4de73f43e9a6a49258fdde1564": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "Downloading: 100%", "description_tooltip": null, "layout": "IPY_MODEL_aefd11f2a6064021abe18bcabc1aea8f", "max": 466062, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_85a0f4d73a6b40f98772f0961802cd06", "value": 466062}}, "3008dbf77e714373949b46ac1c674f9f": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "Downloading: 100%", "description_tooltip": null, "layout": "IPY_MODEL_c068b3c0e10c4c4682dda3c59a2f5a12", "max": 442, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_66603ee28dd44237826a6a4d490ea4cf", "value": 442}}, "35c7ce391b1b4e93b4fe2bf5fa0bcf37": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "Downloading: 100%", "description_tooltip": null, "layout": "IPY_MODEL_b2fc6c4e317a4e22a86d6f7828e55156", "max": 231508, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_cd28866452154f8ca69314a81498220a", "value": 231508}}, "3e1e116560e64f70a47cde0f53a6422e": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "47be298a1d9d4c5ab94516f0d3212872": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_5937d7a3444b407ea4c111a151cc5b92", "placeholder": "\u200b", "style": "IPY_MODEL_192e47ef101f466caaf27f1746a2c220", "value": " 466k/466k [00:05&lt;00:00, 83.7kB/s]"}}, "50c8cbc8531f488db54343805d09b31c": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_efb4f7c4533e48dd9cc9e42abefc490e", "placeholder": "\u200b", "style": "IPY_MODEL_84360a46055a4bc081b61aa0597d27fb", "value": " 363M/363M [00:06&lt;00:00, 55.6MB/s]"}}, "570f5ce436af4467be44a4b328668212": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_8d9e19a22f8f4cd19a33ae7c94e64263", "IPY_MODEL_50c8cbc8531f488db54343805d09b31c"], "layout": "IPY_MODEL_b8226170403c4a3d9fbc464e315e529a"}}, "5937d7a3444b407ea4c111a151cc5b92": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "5cbc808680924217a7fbd4a947984024": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_ad447e0b2b8545da8b7ce13ab655871e", "placeholder": "\u200b", "style": "IPY_MODEL_81bb9fa6e6964fe39cf77df8fca20343", "value": " 98/98 [00:22&lt;00:00,  4.33it/s]"}}, "65ee33631bda4d579be3b5215ff13aff": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "66603ee28dd44237826a6a4d490ea4cf": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": "initial"}}, "66c00b2818954e2786fa52b1b3e74a0b": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "68d77352054f444687c719251f706c7f": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "7638a5aba4304735bca4d9caf4c4aa9b": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "81bb9fa6e6964fe39cf77df8fca20343": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "81d52ccf5609481c8f3009b1a72d3ab4": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "84360a46055a4bc081b61aa0597d27fb": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "85a0f4d73a6b40f98772f0961802cd06": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": "initial"}}, "8d9e19a22f8f4cd19a33ae7c94e64263": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "Downloading: 100%", "description_tooltip": null, "layout": "IPY_MODEL_26434913a55c4bda95863b72bb03c6f4", "max": 363423424, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_0a2936c4a15a429a9db203e1e618705a", "value": 363423424}}, "8de9d3eaeff448ffa2f15e853cf64884": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "9a991830d54c49cd8c930406342d1d03": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_0ce0e1cd79a245f1b08a42f072ba7ccb", "IPY_MODEL_5cbc808680924217a7fbd4a947984024"], "layout": "IPY_MODEL_8de9d3eaeff448ffa2f15e853cf64884"}}, "a2ad2928a490410c92ef0672e8837e29": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "100%", "description_tooltip": null, "layout": "IPY_MODEL_68d77352054f444687c719251f706c7f", "max": 98, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_ae4b66e36f404d82b48690dfdc203651", "value": 98}}, "a9c8fde5abbc447286380380274e6651": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_2c7f8d4de73f43e9a6a49258fdde1564", "IPY_MODEL_47be298a1d9d4c5ab94516f0d3212872"], "layout": "IPY_MODEL_22534a55b7e545ae8e71b6d0cf0b11f6"}}, "ad447e0b2b8545da8b7ce13ab655871e": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "ae4b66e36f404d82b48690dfdc203651": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": "initial"}}, "aefd11f2a6064021abe18bcabc1aea8f": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b2fc6c4e317a4e22a86d6f7828e55156": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b8226170403c4a3d9fbc464e315e529a": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "bc3bdd4f85a1487ebfc79c6e3284a4a1": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "bfb4a03700b94d9c829ece9d69424ad6": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_35c7ce391b1b4e93b4fe2bf5fa0bcf37", "IPY_MODEL_d5ccc534b007469a809a3a353d8a8841"], "layout": "IPY_MODEL_bc3bdd4f85a1487ebfc79c6e3284a4a1"}}, "c068b3c0e10c4c4682dda3c59a2f5a12": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c17adb97bc994ad18c7d7ddd4d5802df": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_a2ad2928a490410c92ef0672e8837e29", "IPY_MODEL_1fad94ebb7d34d519b541460d0fc2cb2"], "layout": "IPY_MODEL_3e1e116560e64f70a47cde0f53a6422e"}}, "cd28866452154f8ca69314a81498220a": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": "initial"}}, "cd6ed3656a964fdab5812f384d02c96f": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_3008dbf77e714373949b46ac1c674f9f", "IPY_MODEL_d28330616d4e4540b2d8f38b5029cb3e"], "layout": "IPY_MODEL_66c00b2818954e2786fa52b1b3e74a0b"}}, "d065e050632946c2848a7d2adc851dfd": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": "initial"}}, "d28330616d4e4540b2d8f38b5029cb3e": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_7638a5aba4304735bca4d9caf4c4aa9b", "placeholder": "\u200b", "style": "IPY_MODEL_24a58800efe5498296f2e0380c459196", "value": " 442/442 [00:13&lt;00:00, 33.6B/s]"}}, "d5a6f36eb4e849bfb1ab700ae09e404e": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "d5ccc534b007469a809a3a353d8a8841": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_110b4276cae944ab971edf5325fd4cca", "placeholder": "\u200b", "style": "IPY_MODEL_81d52ccf5609481c8f3009b1a72d3ab4", "value": " 232k/232k [00:20&lt;00:00, 11.2kB/s]"}}, "e526a70702ef4c4c9c67389891ba5309": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "efb4f7c4533e48dd9cc9e42abefc490e": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}}
</script>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="ashish244co/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/jupyter/2020/12/30/sentiment-classification-IMDB.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Project Portfolio</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"></ul>
</div>

  </div>

</footer>
</body>

</html>
