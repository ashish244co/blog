{
  
    
        "post0": {
            "title": "Title",
            "content": "Bank Loan Prection . Relationship managers at a bank who operate in the small business segment have a large customer portfolio. Because of this, he/she can currently only reactively serve customers. The current experiment is set up to look for solutions that can help the relationship manager to more proactively serve his customers. . !pip install boruta . Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/ Requirement already satisfied: boruta in /usr/local/lib/python3.7/dist-packages (0.3) Requirement already satisfied: scikit-learn&gt;=0.17.1 in /usr/local/lib/python3.7/dist-packages (from boruta) (1.0.2) Requirement already satisfied: scipy&gt;=0.17.0 in /usr/local/lib/python3.7/dist-packages (from boruta) (1.7.3) Requirement already satisfied: numpy&gt;=1.10.4 in /usr/local/lib/python3.7/dist-packages (from boruta) (1.21.6) Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&gt;=0.17.1-&gt;boruta) (1.1.0) Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&gt;=0.17.1-&gt;boruta) (3.1.0) . !pip install hyperopt . Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/ Requirement already satisfied: hyperopt in /usr/local/lib/python3.7/dist-packages (0.1.2) Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt) (2.6.3) Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.15.0) Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.21.6) Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.7.3) Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt) (4.1.1) Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt) (4.64.0) Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt) (0.16.0) . !pip install catboost . Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/ Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (1.0.6) Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0) Requirement already satisfied: pandas&gt;=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5) Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0) Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2) Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.7.3) Requirement already satisfied: numpy&gt;=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6) Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1) Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.24.0-&gt;catboost) (2022.1) Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.24.0-&gt;catboost) (2.8.2) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;catboost) (1.4.3) Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;catboost) (0.11.0) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;catboost) (3.0.9) Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib-&gt;catboost) (4.1.1) Requirement already satisfied: tenacity&gt;=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly-&gt;catboost) (8.0.1) . !pip install shap . Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/ Requirement already satisfied: shap in /usr/local/lib/python3.7/dist-packages (0.41.0) Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.5) Requirement already satisfied: packaging&gt;20.9 in /usr/local/lib/python3.7/dist-packages (from shap) (21.3) Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.7.3) Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.21.6) Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.7/dist-packages (from shap) (0.0.7) Requirement already satisfied: tqdm&gt;4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.64.0) Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0) Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2) Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (1.0.2) Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging&gt;20.9-&gt;shap) (3.0.9) Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba-&gt;shap) (57.4.0) Requirement already satisfied: llvmlite&lt;0.35,&gt;=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba-&gt;shap) (0.34.0) Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;shap) (2022.1) Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;shap) (2.8.2) Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;shap) (1.15.0) Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-&gt;shap) (3.1.0) Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-&gt;shap) (1.1.0) . import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt from xgboost import XGBClassifier from boruta import BorutaPy from hyperopt import tpe, hp, fmin, STATUS_OK,Trials from hyperopt.pyll.base import scope from sklearn.model_selection import cross_val_score from sklearn.metrics import classification_report from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import train_test_split from sklearn.ensemble import GradientBoostingClassifier from sklearn.metrics import f1_score from hyperopt import space_eval from catboost import CatBoostClassifier import joblib import warnings warnings.filterwarnings(&quot;ignore&quot;) import shap shap.initjs() . credit=pd.read_csv(&quot;credit_applications.csv&quot;) . cust=pd.read_csv(&quot;customers.csv&quot;) . cust.head() . Unnamed: 0 client_nr yearmonth total_nr_trx nr_debit_trx volume_debit_trx nr_credit_trx volume_credit_trx min_balance max_balance CRG . 0 1 | 1 | 201401 | 97 | 50 | 6527929 | 47 | 7454863 | -7914288 | 25110651 | 1.0 | . 1 2 | 1 | 201402 | 88 | 59 | 3475918 | 29 | 1895848 | -8448513 | 25036651 | 1.0 | . 2 3 | 1 | 201403 | 96 | 62 | 31316405 | 34 | 20083583 | -10347650 | 18020151 | 1.0 | . 3 4 | 1 | 201404 | 83 | 53 | 18669967 | 30 | 1091295 | -15385039 | 13318200 | 1.0 | . 4 5 | 1 | 201405 | 94 | 54 | 2893905 | 40 | 2034075 | -15682170 | 2350000 | 1.0 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; cust.drop([&#39;Unnamed: 0&#39;,&#39;client_nr&#39;,&#39;yearmonth&#39;,&#39;CRG&#39;],axis=1).describe() . total_nr_trx nr_debit_trx volume_debit_trx nr_credit_trx volume_credit_trx min_balance max_balance . count 29996.000000 | 29996.000000 | 2.999600e+04 | 29996.000000 | 2.999600e+04 | 2.999600e+04 | 2.999600e+04 | . mean 166.427957 | 75.785571 | 1.121290e+07 | 90.642386 | 1.126906e+07 | -5.523773e+06 | 3.752693e+06 | . std 220.947519 | 60.063496 | 1.617596e+07 | 192.244770 | 1.624998e+07 | 1.357517e+07 | 1.616937e+07 | . min 1.000000 | 0.000000 | 0.000000e+00 | 0.000000 | 0.000000e+00 | -3.467127e+08 | -2.485206e+08 | . 25% 76.000000 | 38.000000 | 3.072750e+06 | 33.000000 | 3.148068e+06 | -7.895864e+06 | -1.868002e+06 | . 50% 129.000000 | 66.000000 | 6.822769e+06 | 56.000000 | 6.934694e+06 | -2.957198e+06 | 1.040998e+06 | . 75% 205.000000 | 101.000000 | 1.386656e+07 | 102.000000 | 1.394257e+07 | 1.690275e+04 | 5.806224e+06 | . max 6341.000000 | 1590.000000 | 7.980480e+08 | 6325.000000 | 8.775321e+08 | 2.109783e+08 | 3.722319e+08 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; some extreme values prsent for transactional behavior . cust.isna().sum() . Unnamed: 0 0 client_nr 0 yearmonth 0 total_nr_trx 0 nr_debit_trx 0 volume_debit_trx 0 nr_credit_trx 0 volume_credit_trx 0 min_balance 0 max_balance 0 CRG 5537 dtype: int64 . seems like Credit risk group variable have some missing values. Instead of dropping or filling with the mode we shall assign a different category to them. . cust.groupby([&#39;client_nr&#39;])[&#39;yearmonth&#39;].nunique().describe() . count 992.000000 mean 30.237903 std 5.742178 min 1.000000 25% 32.000000 50% 32.000000 75% 32.000000 max 32.000000 Name: yearmonth, dtype: float64 . this show some clients do not have full time series. We can drop those clients but we can keep as well, its a subjective choice. . . . . full=cust.drop(&quot;Unnamed: 0&quot;,axis=1).merge(credit.drop(&quot;Unnamed: 0&quot;,axis=1),on=[&#39;yearmonth&#39;,&#39;client_nr&#39;]) . full[&#39;Date&#39;]=pd.to_datetime(full[&#39;yearmonth&#39;].astype(str), format=&#39;%Y%m&#39;) . max(full[&#39;Date&#39;]) . Timestamp(&#39;2016-08-01 00:00:00&#39;) . min(full[&#39;Date&#39;]) . Timestamp(&#39;2014-01-01 00:00:00&#39;) . full.groupby(&#39;Date&#39;)[&#39;nr_credit_applications&#39;].sum().reset_index().sort_values(by=&#39;nr_credit_applications&#39;,ascending=False) . Date nr_credit_applications . 18 2015-07-01 | 120 | . 17 2015-06-01 | 120 | . 21 2015-10-01 | 99 | . 11 2014-12-01 | 96 | . 4 2014-05-01 | 96 | . 8 2014-09-01 | 96 | . 5 2014-06-01 | 91 | . 6 2014-07-01 | 89 | . 16 2015-05-01 | 88 | . 22 2015-11-01 | 87 | . 14 2015-03-01 | 87 | . 10 2014-11-01 | 87 | . 9 2014-10-01 | 87 | . 12 2015-01-01 | 86 | . 20 2015-09-01 | 82 | . 3 2014-04-01 | 82 | . 28 2016-05-01 | 81 | . 23 2015-12-01 | 81 | . 15 2015-04-01 | 80 | . 7 2014-08-01 | 80 | . 24 2016-01-01 | 79 | . 29 2016-06-01 | 78 | . 26 2016-03-01 | 77 | . 1 2014-02-01 | 73 | . 2 2014-03-01 | 72 | . 19 2015-08-01 | 70 | . 13 2015-02-01 | 68 | . 27 2016-04-01 | 67 | . 0 2014-01-01 | 66 | . 30 2016-07-01 | 59 | . 25 2016-02-01 | 45 | . 31 2016-08-01 | 43 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; full=full.sort_values(by=[&#39;client_nr&#39;,&#39;Date&#39;]) . full[&#39;month&#39;]=pd.DatetimeIndex(full[&#39;Date&#39;]).month . full[&#39;month&#39;]=full[&#39;month&#39;].astype(&#39;category&#39;) . full.groupby(&#39;month&#39;)[&#39;nr_credit_applications&#39;].sum().reset_index().sort_values(by=&#39;nr_credit_applications&#39;,ascending=False) . month nr_credit_applications . 5 6 | 289 | . 6 7 | 268 | . 4 5 | 265 | . 2 3 | 236 | . 0 1 | 231 | . 3 4 | 229 | . 7 8 | 193 | . 1 2 | 186 | . 9 10 | 186 | . 8 9 | 178 | . 11 12 | 177 | . 10 11 | 174 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; generally we see that from august there is a drop in applications of loans. so we can use the variable month as it can be useful. . full[&#39;cash_flow&#39;]=full[&#39;volume_credit_trx&#39;]-full[&#39;volume_debit_trx&#39;] . we also caculate a feature called cash flow which define the net earnings of the clients for that timestamp and which keeps on getting accumalated. . full.drop([&#39;yearmonth&#39;],axis=1,inplace=True) . full[&#39;month&#39;]=full[&#39;month&#39;].astype(str) . full[&#39;CRG&#39;]=full[&#39;CRG&#39;].astype(&#39;category&#39;) full[&#39;CRG&#39;].unique() . [1.0, 4.0, 7.0, 2.0, 3.0, 5.0, NaN] Categories (6, float64): [1.0, 2.0, 3.0, 4.0, 5.0, 7.0] . full[&#39;CRG&#39;] = full[&#39;CRG&#39;].cat.add_categories(-1) full[&#39;CRG&#39;].fillna(-1, inplace=True) . we also try to inspect how crg groups behave differently for different transactions dimensions. . sns.boxplot(x=&#39;CRG&#39;,y=&#39;min_balance&#39;,data=full) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f0887706d90&gt; . sns.boxplot(x=&#39;CRG&#39;,y=&#39;cash_flow&#39;,data=full) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f088746ca50&gt; . full.groupby(&#39;CRG&#39;)[&#39;client_nr&#39;].nunique().reset_index().sort_values(by=&#39;client_nr&#39;,ascending=False) . CRG client_nr . 2 3.0 | 291 | . 6 -1.0 | 194 | . 0 1.0 | 140 | . 5 7.0 | 138 | . 1 2.0 | 136 | . 3 4.0 | 68 | . 4 5.0 | 25 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; full.groupby(&#39;CRG&#39;)[&#39;nr_credit_applications&#39;].sum().reset_index().sort_values(by=&#39;nr_credit_applications&#39;,ascending=False) . CRG nr_credit_applications . 2 3.0 | 756 | . 5 7.0 | 614 | . 1 2.0 | 415 | . 3 4.0 | 290 | . 6 -1.0 | 217 | . 0 1.0 | 186 | . 4 5.0 | 134 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; there is good amount of variation with respect to the column crg so it is worthwile to keep the variable. on a general level it might be the case that the crg group 3 must be more trustable as compared to group 7. . diff=full[full[&#39;credit_application&#39;]==1] . diff[&#39;Prev&#39;]=diff.groupby(&#39;client_nr&#39;)[&#39;Date&#39;].shift(1) . diff=diff[[&#39;client_nr&#39;,&#39;Date&#39;,&#39;Prev&#39;]].fillna(&#39;2014-01-01&#39;) . diff[&#39;consec&#39;]=(diff[&#39;Date&#39;]-diff[&#39;Prev&#39;])// np.timedelta64(1, &#39;M&#39;) . sns.distplot(diff[&#39;consec&#39;],kde=False) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f08875e53d0&gt; . diff.head() . client_nr Date Prev consec . 70 3 | 2014-07-01 | 2014-01-01 | 5 | . 81 3 | 2015-06-01 | 2014-07-01 | 11 | . 87 3 | 2015-12-01 | 2015-06-01 | 6 | . 95 3 | 2016-08-01 | 2015-12-01 | 8 | . 126 4 | 2016-07-01 | 2014-01-01 | 29 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; diff[&#39;consec&#39;].describe() . count 2025.000000 mean 5.841975 std 5.668782 min 0.000000 25% 2.000000 50% 4.000000 75% 8.000000 max 30.000000 Name: consec, dtype: float64 . from above we see that generally different between consective loans can be generally around 8 months. This information is useful to decide for the forecasting window that we should choose. . full[&#39;avg_local_credit&#39;]=full[&#39;volume_credit_trx&#39;]/full[&#39;nr_credit_trx&#39;] full[&#39;avg_local_debit&#39;]=full[&#39;volume_debit_trx&#39;]/full[&#39;nr_debit_trx&#39;] . full[&#39;nr_credit_applications_cumsum&#39;]=full.groupby(&#39;client_nr&#39;)[&#39;nr_credit_applications&#39;].cumsum() . full[&#39;cash_flow_cumsum&#39;]=full.groupby(&#39;client_nr&#39;)[&#39;cash_flow&#39;].cumsum() . full[&#39;nr_debit_trx_cumsum&#39;]=full.groupby(&#39;client_nr&#39;)[&#39;nr_debit_trx&#39;].cumsum() full[&#39;nr_credit_trx_cumsum&#39;]=full.groupby(&#39;client_nr&#39;)[&#39;nr_credit_trx&#39;].cumsum() . full[&#39;volume_debit_trx_cumsum&#39;]=full.groupby(&#39;client_nr&#39;)[&#39;volume_debit_trx&#39;].cumsum() full[&#39;volume_credit_trx_cumsum&#39;]=full.groupby(&#39;client_nr&#39;)[&#39;volume_credit_trx&#39;].cumsum() full[&#39;avg_global_credit&#39;]=full[&#39;volume_credit_trx_cumsum&#39;]/full[&#39;nr_credit_trx_cumsum&#39;] full[&#39;avg_global_debit&#39;]=full[&#39;volume_debit_trx_cumsum&#39;]/full[&#39;nr_debit_trx_cumsum&#39;] . full[&#39;global_min_balance&#39;]=full.groupby(&#39;client_nr&#39;)[&#39;min_balance&#39;].cummin() . full[&#39;global_max_balance&#39;]=full.groupby(&#39;client_nr&#39;)[&#39;max_balance&#39;].cummax() . def create_shifted_lables(data,n): data[&#39;T+&#39;+str(n)+&#39;_nr_credit_applications&#39;]=data.groupby(&#39;client_nr&#39;)[&#39;nr_credit_applications&#39;].shift(-n) . we calcalate some variables as above on a cumulative value so that at each time stamp we can also have historical information with use which will help us in predicting the future actions of the clients. . for i in range(1,13): create_shifted_lables(full,i) . we manipulate data to create target variable such as number of loans taken in the future at t+n timestamp which will be use to predict. . full.columns . Index([&#39;client_nr&#39;, &#39;total_nr_trx&#39;, &#39;nr_debit_trx&#39;, &#39;volume_debit_trx&#39;, &#39;nr_credit_trx&#39;, &#39;volume_credit_trx&#39;, &#39;min_balance&#39;, &#39;max_balance&#39;, &#39;CRG&#39;, &#39;credit_application&#39;, &#39;nr_credit_applications&#39;, &#39;Date&#39;, &#39;month&#39;, &#39;cash_flow&#39;, &#39;avg_local_credit&#39;, &#39;avg_local_debit&#39;, &#39;nr_credit_applications_cumsum&#39;, &#39;cash_flow_cumsum&#39;, &#39;nr_debit_trx_cumsum&#39;, &#39;nr_credit_trx_cumsum&#39;, &#39;volume_debit_trx_cumsum&#39;, &#39;volume_credit_trx_cumsum&#39;, &#39;avg_global_credit&#39;, &#39;avg_global_debit&#39;, &#39;global_min_balance&#39;, &#39;global_max_balance&#39;, &#39;T+1_nr_credit_applications&#39;, &#39;T+2_nr_credit_applications&#39;, &#39;T+3_nr_credit_applications&#39;, &#39;T+4_nr_credit_applications&#39;, &#39;T+5_nr_credit_applications&#39;, &#39;T+6_nr_credit_applications&#39;, &#39;T+7_nr_credit_applications&#39;, &#39;T+8_nr_credit_applications&#39;, &#39;T+9_nr_credit_applications&#39;, &#39;T+10_nr_credit_applications&#39;, &#39;T+11_nr_credit_applications&#39;, &#39;T+12_nr_credit_applications&#39;], dtype=&#39;object&#39;) . full.groupby(&#39;client_nr&#39;)[&#39;nr_credit_applications&#39;].sum().describe() . count 992.000000 mean 2.633065 std 3.412808 min 0.000000 25% 0.000000 50% 1.000000 75% 4.000000 max 27.000000 Name: nr_credit_applications, dtype: float64 . we see that moslty people took number of loans between 1 to 4. We will take two such customers to see if we can find reason or pattern why they took specified number of loans. . clients=full.groupby(&#39;client_nr&#39;)[&#39;nr_credit_applications&#39;].sum().reset_index() . clients[clients[&#39;nr_credit_applications&#39;]==4] . client_nr nr_credit_applications . 40 41 | 4 | . 46 47 | 4 | . 60 61 | 4 | . 73 74 | 4 | . 82 83 | 4 | . ... ... | ... | . 890 895 | 4 | . 909 914 | 4 | . 912 917 | 4 | . 939 945 | 4 | . 965 973 | 4 | . 78 rows × 2 columns . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; cleints_one_loan=clients[clients[&#39;nr_credit_applications&#39;]==1] . cleints_one_loan.head() . client_nr nr_credit_applications . 3 4 | 1 | . 5 6 | 1 | . 7 8 | 1 | . 24 25 | 1 | . 30 31 | 1 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Client with only 1 loan . sns.scatterplot(data=full[full[&#39;client_nr&#39;]==6], x=&quot;Date&quot;, y=&#39;cash_flow_cumsum&#39;,hue=&#39;credit_application&#39;) plt.show() . sns.scatterplot(data=full[full[&#39;client_nr&#39;]==6], x=&quot;Date&quot;, y=&#39;min_balance&#39;,hue=&#39;credit_application&#39;) plt.show() . client with 4 loans . sns.scatterplot(data=full[full[&#39;client_nr&#39;]==47], x=&quot;Date&quot;, y=&#39;cash_flow_cumsum&#39;,hue=&#39;credit_application&#39;) plt.show() . sns.scatterplot(data=full[full[&#39;client_nr&#39;]==47], x=&quot;Date&quot;, y=&#39;min_balance&#39;,hue=&#39;credit_application&#39;) plt.show() . one interesting pattern to see here is that the users who took more loans are the one for whome cash flow cumulative increase which means for whome income increase more. . full[[&#39;T+1_nr_credit_applications&#39;, &#39;T+2_nr_credit_applications&#39;, &#39;T+3_nr_credit_applications&#39;, &#39;T+4_nr_credit_applications&#39;, &#39;T+5_nr_credit_applications&#39;, &#39;T+6_nr_credit_applications&#39;, &#39;T+7_nr_credit_applications&#39;, &#39;T+8_nr_credit_applications&#39;, &#39;T+9_nr_credit_applications&#39;, &#39;T+10_nr_credit_applications&#39;, &#39;T+11_nr_credit_applications&#39;, &#39;T+12_nr_credit_applications&#39;]]=full[[&#39;T+1_nr_credit_applications&#39;, &#39;T+2_nr_credit_applications&#39;, &#39;T+3_nr_credit_applications&#39;, &#39;T+4_nr_credit_applications&#39;, &#39;T+5_nr_credit_applications&#39;, &#39;T+6_nr_credit_applications&#39;, &#39;T+7_nr_credit_applications&#39;, &#39;T+8_nr_credit_applications&#39;, &#39;T+9_nr_credit_applications&#39;, &#39;T+10_nr_credit_applications&#39;, &#39;T+11_nr_credit_applications&#39;, &#39;T+12_nr_credit_applications&#39;]].fillna(0) . full[[&#39;avg_local_credit&#39;,&#39;avg_local_debit&#39;,&#39;avg_global_credit&#39;,&#39;avg_global_debit&#39;]]=full[[&#39;avg_local_credit&#39;,&#39;avg_local_debit&#39;,&#39;avg_global_credit&#39;,&#39;avg_global_debit&#39;]].fillna(0) . full.isna().sum() . client_nr 0 total_nr_trx 0 nr_debit_trx 0 volume_debit_trx 0 nr_credit_trx 0 volume_credit_trx 0 min_balance 0 max_balance 0 CRG 0 credit_application 0 nr_credit_applications 0 Date 0 month 0 cash_flow 0 avg_local_credit 0 avg_local_debit 0 nr_credit_applications_cumsum 0 cash_flow_cumsum 0 nr_debit_trx_cumsum 0 nr_credit_trx_cumsum 0 volume_debit_trx_cumsum 0 volume_credit_trx_cumsum 0 avg_global_credit 0 avg_global_debit 0 global_min_balance 0 global_max_balance 0 T+1_nr_credit_applications 0 T+2_nr_credit_applications 0 T+3_nr_credit_applications 0 T+4_nr_credit_applications 0 T+5_nr_credit_applications 0 T+6_nr_credit_applications 0 T+7_nr_credit_applications 0 T+8_nr_credit_applications 0 T+9_nr_credit_applications 0 T+10_nr_credit_applications 0 T+11_nr_credit_applications 0 T+12_nr_credit_applications 0 dtype: int64 . full[&#39;CRG&#39;]=full[&#39;CRG&#39;].astype(str) . instead of predicting number of exact loans at t+n timestep we instead use number of loans in next month, next 3 months, next 6 month and next 12 months for better predictibility. . full[&#39;next_month_nr_credit_applications&#39;]=full[&#39;T+1_nr_credit_applications&#39;] . full[&#39;next_3_month_nr_credit_applications&#39;]=full[&#39;T+1_nr_credit_applications&#39;]+full[&#39;T+2_nr_credit_applications&#39;]+full[&#39;T+3_nr_credit_applications&#39;] . full[&#39;next_6_month_nr_credit_applications&#39;]=full[&#39;T+1_nr_credit_applications&#39;]+full[&#39;T+2_nr_credit_applications&#39;]+full[&#39;T+3_nr_credit_applications&#39;]+full[&#39;T+4_nr_credit_applications&#39;]+full[&#39;T+5_nr_credit_applications&#39;]+full[&#39;T+6_nr_credit_applications&#39;] . full[&#39;next_12_month_nr_credit_applications&#39;]=full[&#39;T+1_nr_credit_applications&#39;]+full[&#39;T+2_nr_credit_applications&#39;]+full[&#39;T+3_nr_credit_applications&#39;]+full[&#39;T+4_nr_credit_applications&#39;]+full[&#39;T+5_nr_credit_applications&#39;]+full[&#39;T+6_nr_credit_applications&#39;]+full[&#39;T+7_nr_credit_applications&#39;]+full[&#39;T+8_nr_credit_applications&#39;]+full[&#39;T+9_nr_credit_applications&#39;]+full[&#39;T+10_nr_credit_applications&#39;]+full[&#39;T+11_nr_credit_applications&#39;]+full[&#39;T+12_nr_credit_applications&#39;] . max(full[&#39;Date&#39;]) . Timestamp(&#39;2016-08-01 00:00:00&#39;) . to showcase the thought process we will predict for future 6 months. . full=full[full[&#39;Date&#39;]&lt;=&#39;2016-02-01&#39;] . full.head() . client_nr total_nr_trx nr_debit_trx volume_debit_trx nr_credit_trx volume_credit_trx min_balance max_balance CRG credit_application ... T+7_nr_credit_applications T+8_nr_credit_applications T+9_nr_credit_applications T+10_nr_credit_applications T+11_nr_credit_applications T+12_nr_credit_applications next_month_nr_credit_applications next_3_month_nr_credit_applications next_6_month_nr_credit_applications next_12_month_nr_credit_applications . 0 1 | 97 | 50 | 6527929 | 47 | 7454863 | -7914288 | 25110651 | 1.0 | 0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1 1 | 88 | 59 | 3475918 | 29 | 1895848 | -8448513 | 25036651 | 1.0 | 0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 2 1 | 96 | 62 | 31316405 | 34 | 20083583 | -10347650 | 18020151 | 1.0 | 0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 3 1 | 83 | 53 | 18669967 | 30 | 1091295 | -15385039 | 13318200 | 1.0 | 0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 4 1 | 94 | 54 | 2893905 | 40 | 2034075 | -15682170 | 2350000 | 1.0 | 0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 5 rows × 42 columns . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; X=full.drop([&#39;T+1_nr_credit_applications&#39;,&#39;T+2_nr_credit_applications&#39;,&#39;T+3_nr_credit_applications&#39;,&#39;T+4_nr_credit_applications&#39;,&#39;T+5_nr_credit_applications&#39;,&#39;T+6_nr_credit_applications&#39;,&#39;T+7_nr_credit_applications&#39;,&#39;T+8_nr_credit_applications&#39;,&#39;T+9_nr_credit_applications&#39;,&#39;T+10_nr_credit_applications&#39;,&#39;T+11_nr_credit_applications&#39;,&#39;T+12_nr_credit_applications&#39;],axis=1) . X.columns . Index([&#39;client_nr&#39;, &#39;total_nr_trx&#39;, &#39;nr_debit_trx&#39;, &#39;volume_debit_trx&#39;, &#39;nr_credit_trx&#39;, &#39;volume_credit_trx&#39;, &#39;min_balance&#39;, &#39;max_balance&#39;, &#39;CRG&#39;, &#39;credit_application&#39;, &#39;nr_credit_applications&#39;, &#39;Date&#39;, &#39;month&#39;, &#39;cash_flow&#39;, &#39;avg_local_credit&#39;, &#39;avg_local_debit&#39;, &#39;nr_credit_applications_cumsum&#39;, &#39;cash_flow_cumsum&#39;, &#39;nr_debit_trx_cumsum&#39;, &#39;nr_credit_trx_cumsum&#39;, &#39;volume_debit_trx_cumsum&#39;, &#39;volume_credit_trx_cumsum&#39;, &#39;avg_global_credit&#39;, &#39;avg_global_debit&#39;, &#39;global_min_balance&#39;, &#39;global_max_balance&#39;, &#39;next_month_nr_credit_applications&#39;, &#39;next_3_month_nr_credit_applications&#39;, &#39;next_6_month_nr_credit_applications&#39;, &#39;next_12_month_nr_credit_applications&#39;], dtype=&#39;object&#39;) . X=X.drop(columns= [&#39;next_month_nr_credit_applications&#39;,&#39;next_3_month_nr_credit_applications&#39;,&#39;next_6_month_nr_credit_applications&#39;,&#39;next_12_month_nr_credit_applications&#39;,&#39;client_nr&#39;,&#39;Date&#39;,&#39;credit_application&#39;, &#39;total_nr_trx&#39;,&#39;volume_debit_trx_cumsum&#39;,&#39;nr_credit_trx_cumsum&#39; ],axis=1) . X.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 24370 entries, 0 to 29989 Data columns (total 20 columns): # Column Non-Null Count Dtype -- -- 0 nr_debit_trx 24370 non-null int64 1 volume_debit_trx 24370 non-null int64 2 nr_credit_trx 24370 non-null int64 3 volume_credit_trx 24370 non-null int64 4 min_balance 24370 non-null int64 5 max_balance 24370 non-null int64 6 CRG 24370 non-null object 7 nr_credit_applications 24370 non-null int64 8 month 24370 non-null object 9 cash_flow 24370 non-null int64 10 avg_local_credit 24370 non-null float64 11 avg_local_debit 24370 non-null float64 12 nr_credit_applications_cumsum 24370 non-null int64 13 cash_flow_cumsum 24370 non-null int64 14 nr_debit_trx_cumsum 24370 non-null int64 15 volume_credit_trx_cumsum 24370 non-null int64 16 avg_global_credit 24370 non-null float64 17 avg_global_debit 24370 non-null float64 18 global_min_balance 24370 non-null int64 19 global_max_balance 24370 non-null int64 dtypes: float64(4), int64(14), object(2) memory usage: 3.9+ MB . we binarise the variable . y=(full[[&#39;next_6_month_nr_credit_applications&#39;]]&gt;=1).astype(int) . X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.1) . we create a train dataset, validation set ( for hyperparameter tuning) and a test set. . X_val=X_train[-1000:] y_val=y_train[-1000:] X_train=X_train[:-1000] y_train=y_train[:-1000] . rf=RandomForestClassifier(n_estimators=500,max_depth=10,class_weight=&#39;balanced&#39;) rf.fit(X_train,y_train) %time print(classification_report(y_test, rf.predict_proba(X_test)[:,1]&gt;=0.5, target_names=[&quot;0&quot;,&quot;1&quot;])) . CPU times: user 3 µs, sys: 0 ns, total: 3 µs Wall time: 6.2 µs precision recall f1-score support 0 0.89 0.78 0.83 1685 1 0.61 0.79 0.69 752 accuracy 0.78 2437 macro avg 0.75 0.78 0.76 2437 weighted avg 0.80 0.78 0.78 2437 . above we casually fit a model lets see how much score we can improve with further hyperparameter tuning and ensembling. . space_RF = { &quot;n_estimators&quot;: hp.choice(&quot;n_estimators&quot;, [300, 400,500,600,700,800,900,1000]), &quot;max_depth&quot;: hp.quniform(&quot;max_depth&quot;, 5, 15,1) } . def parameter_tuning_RF(params): clf = RandomForestClassifier(**params,class_weight=&#39;balanced&#39;,n_jobs=-1) f1 = cross_val_score(clf, X_train, y_train,scoring=&quot;f1_weighted&quot;,cv=3).mean() return {&quot;loss&quot;: -f1, &quot;status&quot;: STATUS_OK} . trials = Trials() best_RF = fmin( fn=parameter_tuning_RF, space = space_RF, algo=tpe.suggest, max_evals=30, trials=trials ) print(&quot;Best: {}&quot;.format(best_RF)) . 100%|██████████| 30/30 [27:21&lt;00:00, 54.73s/it, best loss: -0.8248557350549816] Best: {&#39;max_depth&#39;: 15.0, &#39;n_estimators&#39;: 3} . hyperparams = space_eval(space_RF,best_RF) . hyperparams . {&#39;max_depth&#39;: 15.0, &#39;n_estimators&#39;: 600} . we also perform feature selection and feature ranking. . def feature_selector(clf,x,y): boruta = BorutaPy(estimator = clf, n_estimators = &#39;auto&#39;, max_iter = 50) boruta.fit(x.values, y.values) important = list(X.columns[boruta.support_]) print(f&quot;important: {important}&quot;) tentative = list(X.columns[boruta.support_weak_]) print(f&quot;unconfirmed: {tentative}&quot;) unimportant = list(X.columns[~(boruta.support_ | boruta.support_weak_)]) print(f&quot;unimportant: {unimportant}&quot;) important.extend(tentative) return important,boruta.ranking_ . clf=RandomForestClassifier(**hyperparams,class_weight=&#39;balanced&#39;,n_jobs=-1) . featuresrf,ranking=feature_selector(clf,X_train,y_train) . important: [&#39;nr_debit_trx&#39;, &#39;volume_debit_trx&#39;, &#39;nr_credit_trx&#39;, &#39;volume_credit_trx&#39;, &#39;min_balance&#39;, &#39;max_balance&#39;, &#39;CRG&#39;, &#39;avg_local_credit&#39;, &#39;avg_local_debit&#39;, &#39;nr_credit_applications_cumsum&#39;, &#39;cash_flow_cumsum&#39;, &#39;nr_debit_trx_cumsum&#39;, &#39;volume_credit_trx_cumsum&#39;, &#39;avg_global_credit&#39;, &#39;avg_global_debit&#39;, &#39;global_min_balance&#39;, &#39;global_max_balance&#39;] unconfirmed: [&#39;cash_flow&#39;] unimportant: [&#39;nr_credit_applications&#39;, &#39;month&#39;] . X_train_rf=X_train.loc[:,featuresrf] X_val_rf=X_val.loc[:,featuresrf] X_test_rf=X_test.loc[:,featuresrf] . clf=RandomForestClassifier(**hyperparams,class_weight=&#39;balanced&#39;,n_jobs=-1) . clf.fit(X_train_rf,y_train) . RandomForestClassifier(class_weight=&#39;balanced&#39;, max_depth=15.0, n_estimators=600, n_jobs=-1) . we also try to find the best threshold which will emphasise on the weighted f1 score. . maxargrf=0.4 max_score=-1 for i in np.arange(0.4, 0.7, 0.01): score=f1_score(y_val, clf.predict_proba(X_val_rf)[:,1]&gt;=i, average=&#39;weighted&#39;) if(score&gt;max_score): max_score=score maxargrf=i . maxargrf . 0.5400000000000001 . %time print(classification_report(y_test, clf.predict_proba(X_test_rf)[:,1]&gt;=maxargrf, target_names=[&quot;0&quot;,&quot;1&quot;])) . CPU times: user 5 µs, sys: 0 ns, total: 5 µs Wall time: 9.78 µs precision recall f1-score support 0 0.89 0.91 0.90 1685 1 0.78 0.76 0.77 752 accuracy 0.86 2437 macro avg 0.84 0.83 0.83 2437 weighted avg 0.86 0.86 0.86 2437 . len(y[y[&#39;next_6_month_nr_credit_applications&#39;]==1]) . 7523 . len(y[y[&#39;next_6_month_nr_credit_applications&#39;]==0]) . 16847 . for catboost classifier we enable early stopping and scale pos parameter which takes care of imbalanced classes. . clf2 = CatBoostClassifier(iterations=10000, learning_rate= 0.01,use_best_model=True,od_type=&#39;Iter&#39;,od_wait=50,scale_pos_weight=2.3) . clf2.fit( X_train, y_train, cat_features=[6,8], plot=True, eval_set=(X_val ,y_val) ) . maxargcat=0.4 max_score=-1 for i in np.arange(0.4, 0.7, 0.01): score=f1_score(y_val, clf2.predict_proba(X_val)[:,1]&gt;=i, average=&#39;weighted&#39;) if(score&gt;max_score): max_score=score maxargcat=i . %time print(classification_report(y_test, clf2.predict(X_test), target_names=[&quot;0&quot;,&quot;1&quot;])) . CPU times: user 5 µs, sys: 1 µs, total: 6 µs Wall time: 9.78 µs precision recall f1-score support 0 0.94 0.86 0.90 1685 1 0.74 0.87 0.80 752 accuracy 0.86 2437 macro avg 0.84 0.86 0.85 2437 weighted avg 0.87 0.86 0.87 2437 . we optimise for a mix paramter which optimises the mix of random forest and catboost on validation set. . scoree=-1 mix=0 for i in np.arange(0, 1, 0.1): j=1-i y_pred=(i*clf.predict_proba(X_val_rf)[:,1]+ j*(clf2.predict_proba(X_val)[:,1]))/(i+j) score=f1_score(y_val, (y_pred&gt;=0.5).astype(int), average=&#39;weighted&#39;) if(score&gt;scoree): scoree=score mix=i . mix . 0.30000000000000004 . y_pred=(mix*clf.predict_proba(X_test_rf)[:,1]+ (1-mix)*(clf2.predict_proba(X_test)[:,1])) . %time print(classification_report(y_test, (y_pred&gt;=0.5).astype(int), target_names=[&quot;0&quot;,&quot;1&quot;])) . CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs Wall time: 5.72 µs precision recall f1-score support 0 0.94 0.87 0.90 1685 1 0.75 0.87 0.80 752 accuracy 0.87 2437 macro avg 0.84 0.87 0.85 2437 weighted avg 0.88 0.87 0.87 2437 . so our model seems to be good just the precision is a bit less as compared to other metrics which can be optimised by raising the threshold as per business needs rest looks good. . explainer = shap.TreeExplainer(clf2) shap_values = explainer.shap_values(X_train) . shap.summary_plot(shap_values, X_train) . abpve shapley plot shows us that how variables affect the output. Its interesting to see the relationship of min/max balance, past credit applications on the output which seems to make sense. . for implementation we can rank the customers based on how high the probablity is to apply for a loans in the coming months, and give attention accordingly. . explainer = shap.TreeExplainer(clf2) shap_values = explainer.shap_values(X_test) shap.summary_plot(shap_values, X_test) . type1=[] type2=[] . from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay . cm=confusion_matrix(y_test, (y_pred&gt;=0.5).astype(int)) . ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=clf2.classes_).plot() . &lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f087e42ad50&gt; . type2=[] . for p, a in zip(y_test.values.squeeze(), (y_pred&gt;=0.5).astype(int)): if((p==0) &amp; (a==1)): type2.append(True) else: type2.append(False) . X_test.loc[type2,:].describe() . nr_debit_trx volume_debit_trx nr_credit_trx volume_credit_trx min_balance max_balance nr_credit_applications cash_flow avg_local_credit avg_local_debit nr_credit_applications_cumsum cash_flow_cumsum nr_debit_trx_cumsum volume_credit_trx_cumsum avg_global_credit avg_global_debit global_min_balance global_max_balance . count 222.000000 | 2.220000e+02 | 222.000000 | 2.220000e+02 | 2.220000e+02 | 2.220000e+02 | 222.000000 | 2.220000e+02 | 222.000000 | 222.000000 | 222.000000 | 2.220000e+02 | 222.000000 | 2.220000e+02 | 222.000000 | 222.000000 | 2.220000e+02 | 2.220000e+02 | . mean 82.707207 | 8.441915e+06 | 74.828829 | 8.622403e+06 | -8.890885e+06 | -7.355832e+05 | 0.220721 | 1.804874e+05 | 123149.532152 | 104135.663538 | 2.139640 | -7.015935e+05 | 1010.144144 | 1.100454e+08 | 125585.619152 | 108206.186392 | -1.261369e+07 | 2.174478e+06 | . std 38.614932 | 6.607415e+06 | 56.483510 | 7.500837e+06 | 8.986808e+06 | 8.609833e+06 | 0.504212 | 3.455147e+06 | 94909.954476 | 72395.136775 | 2.405378 | 5.918188e+06 | 862.287869 | 1.156250e+08 | 75136.408686 | 70961.034486 | 1.395708e+07 | 1.120575e+07 | . min 14.000000 | 6.147450e+05 | 15.000000 | 9.090280e+05 | -5.078090e+07 | -4.457249e+07 | 0.000000 | -6.689391e+06 | 28733.409836 | 12404.829787 | 0.000000 | -3.749371e+07 | 29.000000 | 1.591174e+06 | 26002.477612 | 17515.647655 | -7.685539e+07 | -3.702260e+07 | . 25% 51.250000 | 3.651970e+06 | 37.250000 | 3.671908e+06 | -1.231199e+07 | -3.946260e+06 | 0.000000 | -6.404925e+05 | 69125.290164 | 56458.889923 | 0.000000 | -1.532136e+06 | 342.250000 | 2.207029e+07 | 74317.129575 | 59643.994994 | -1.535338e+07 | -2.244168e+06 | . 50% 73.500000 | 7.283650e+06 | 59.500000 | 6.851706e+06 | -7.074746e+06 | 5.875950e+04 | 0.000000 | 7.080000e+03 | 102942.428150 | 78772.354288 | 1.500000 | -2.734825e+05 | 771.000000 | 6.878834e+07 | 112778.034193 | 88494.956764 | -9.051172e+06 | 8.519360e+05 | . 75% 111.000000 | 1.138326e+07 | 95.000000 | 1.139022e+07 | -3.187168e+06 | 1.479230e+06 | 0.000000 | 5.373035e+05 | 143889.871111 | 134017.040762 | 3.000000 | 5.858578e+05 | 1406.750000 | 1.528945e+08 | 145546.242877 | 141165.532783 | -4.013094e+06 | 4.973174e+06 | . max 217.000000 | 4.332326e+07 | 414.000000 | 5.253854e+07 | 4.357142e+06 | 4.048669e+07 | 3.000000 | 4.358051e+07 | 929674.941176 | 378763.500000 | 15.000000 | 4.263622e+07 | 4328.000000 | 5.971536e+08 | 504657.909091 | 425501.725962 | 5.007770e+05 | 5.993425e+07 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; correct_labe1=[] for p, a in zip(y_test.values.squeeze(), (y_pred&gt;=0.5).astype(int)): if((p==0) &amp; (a==0)): correct_labe1.append(True) else: correct_labe1.append(False) . X_test.loc[correct_labe1,:].describe()[[&#39;cash_flow_cumsum&#39;,&#39;min_balance&#39;]] . cash_flow_cumsum min_balance . count 1.463000e+03 | 1.463000e+03 | . mean -2.712885e+05 | -3.102227e+06 | . std 1.504404e+07 | 1.337984e+07 | . min -3.400017e+08 | -2.512930e+08 | . 25% -2.483418e+06 | -5.124114e+06 | . 50% -6.646800e+04 | -3.054610e+05 | . 75% 1.921716e+06 | 1.480795e+05 | . max 1.272466e+08 | 1.551133e+08 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; X_test.loc[type2,:].describe()[[&#39;cash_flow_cumsum&#39;,&#39;min_balance&#39;]] . cash_flow_cumsum min_balance . count 2.220000e+02 | 2.220000e+02 | . mean -7.015935e+05 | -8.890885e+06 | . std 5.918188e+06 | 8.986808e+06 | . min -3.749371e+07 | -5.078090e+07 | . 25% -1.532136e+06 | -1.231199e+07 | . 50% -2.734825e+05 | -7.074746e+06 | . 75% 5.858578e+05 | -3.187168e+06 | . max 4.263622e+07 | 4.357142e+06 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; sns.distplot(X_test.loc[type2,:].describe()[[&#39;cash_flow_cumsum&#39;]]) sns.distplot(X_test.loc[correct_labe1,:].describe()[[&#39;cash_flow_cumsum&#39;]]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f087fa244d0&gt; . we can see that one possible reason for misclassification (type2) error is that in the test set it was difficult to predict correctly for some examples since distribution of cash_flow_cumsum, min_balance was very wide which kind of hints they were tricky to classify. We can similarly check for other dimensions to inspect why some types of error occured. . . .",
            "url": "https://ashish244co.github.io/blog/2022/07/28/bank-loan-prediction.html",
            "relUrl": "/2022/07/28/bank-loan-prediction.html",
            "date": " • Jul 28, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://ashish244co.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://ashish244co.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "My name is Ashish Kashav. . Find more details here: LinkedIn [^1]. .",
          "url": "https://ashish244co.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ashish244co.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}